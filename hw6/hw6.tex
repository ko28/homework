\documentclass[11pt]{scrartcl}
\usepackage[sexy]{../evan}
\usepackage{cmbright}
\usepackage{cancel}
\usepackage[T1]{fontenc}
%\usepackage{enumerate}
\usepackage[shortlabels]{enumitem}
\usepackage[utf8]{inputenc}
\usepackage[margin=1in]{geometry}
%\usepackage[pdfborder={0 0 0},colorlinks=true,citecolor=red{}]{hyperref}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{setspace}
\usepackage{systeme}
%\usepackage[vlined]{algorithm2e}
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\usepackage{mathtools}
\SetStartEndCondition{ }{}{}%
\SetKwProg{Fn}{def}{\string:}{}
\SetKwFunction{Range}{range}%%
\SetKw{KwTo}{in}\SetKwFor{For}{for}{\string:}{}%
\SetKwIF{If}{ElseIf}{Else}{if}{:}{elif}{else:}{}%
\SetKwFor{While}{while}{:}{fintq}%
\newcommand{\forcond}{$i=0$ \KwTo $n$}
\SetKwFunction{FRecurs}{FnRecursive}%
\AlgoDontDisplayBlockMarkers\SetAlgoNoEnd\SetAlgoNoLine%


\usepackage{xcolor}
\DontPrintSemicolon

% Define pseudocode formatting
\renewcommand{\KwSty}[1]{\textnormal{\textcolor{blue!90!black}{\ttfamily\bfseries #1}}\unskip}
\renewcommand{\ArgSty}[1]{\textnormal{\ttfamily #1}\unskip}
\SetKwComment{Comment}{\color{green!50!black}// }{}
\renewcommand{\CommentSty}[1]{\textnormal{\ttfamily\color{green!50!black}#1}\unskip}
\newcommand{\assign}{\leftarrow}
\newcommand{\var}{\texttt}
\newcommand{\FuncCall}[2]{\texttt{\bfseries #1(#2)}}
\SetKwProg{Function}{function}{}{}
\renewcommand{\ProgSty}[1]{\texttt{\bfseries #1}}



\title{CS 577: HW 6}
\author{Daniel Ko}
\date{Summer 2020}

\begin{document}
\maketitle

%7.16
\section{
  Give an efficient algorithm to decide if this is possible, and if so, to actually choose an ad
  to show each user.
 }

\subsection{
	Construct a network flow model for this problem. Clearly state the
	meaning of each component (node, edge, capacity) of the flow network that you
	construct, present your algorithm in pseudocode, and give the computing complexity
	analysis of your algorithm.
}
We construct a graph $G=(V,E)$ to model the network flow.
\subsubsection{
	Components for graph
}
\begin{enumerate}[label=\alph*.]
	\item{
	      \textbf{Nodes}
	      \begin{itemize}
		      \item Start with a source node $s$.
		      \item Add a column of $n$ nodes, denoted as $u$, to represent the number of users.
		      \item Add a column of $k$ nodes, denoted as $dg$, to represent the number of demographic groups.
		      \item Add a column of $m$ nodes, denoted as $a$, to represent the number of advertisers.
		      \item End with a sink node $t$.
	      \end{itemize}
	      }
	\item{
	      \textbf{Edges and capacities}
	      \begin{itemize}
		      \item{
		            Add an edge from source node $s$ to each user node. Let the capacity of these edges be $1$ to
		            represent that we only want $1$ ad for a user.
		            }
		      \item {
		            Add edges from each user node to the corresponding demographic groups it belongs to.
		            Let the capacity of these edges be $1$ to represent that only $1$ ad for a particular
		            demographic groups can be shown to a user.
		            }
		      \item {
		            Add edges from each demographic groups to each advertiser that wants to show its ads to.
		            Let the capacity of these edges be $r_i$, as we only care about the lower bound of the number of
		            users to show ads.
		            }
		      \item {
		            Add edges from each advertiser to $t$. Let the capacity of these edges be $r_i$,
		            as we only care about the lower bound of the number of
		            users to show ads.
		            }
	      \end{itemize}
	      }
\end{enumerate}
\textbf{add graph picture}
\subsubsection{
	Algorithm and complexity
}
\begin{algorithm}
	\caption{Satisfy advertisers}
	\Comment{$\theta_{\mathrm{exp}}$ is globally given, and initially set to $\infty$.}
	\Comment{$\theta_{\mathrm{exp}}$ is globally given, and initially set to $\infty$.}
	\Comment{$\theta_{\mathrm{exp}}$ is globally given, and initially set to $\infty$.}
	\Function{ConstructGraph($DG$, $X$, $U$, $r$, $m$, $n$)}{
		Let $V$ be a set of vertices, $E$ be a set of edges\;
		Add $s$ and $t$ to $V$\;
		\Comment{Add users}
		\For{$j$ from $1$ to $n$}{
			Add $u_j$ to $V$\;
			Add edge $(s, u_j)$ to $E$ of capacity $1$\;
		}
		\Comment{Add demographic group}
		\For{$i$ from $1$ to $|DG|$}{
			Add $dg_i$ to $V$\;
		}
		\For{$j$ from $1$ to $|U|$}{
			\For{$dg$ in $U_j$}{
				Add edge $(u_j, dg)$ to $E$ of capacity $1$\;
			}
		}
		\Comment{Add advertisers}
		\For{$i$ from $1$ to $m$}{
			Add $a_i$ to $V$\;
			\For{$dg$ in $X_i$}{
				Add edge $(dg, a_i)$ to $E$ of capacity $r_{i}$\;
			}
			Add edge $(a_i, t)$ to $E$ from of capacity $r_{i}$\;
		}
		\Return{$G=(V,E)$}
	}
	\Comment{The main function}
	\Function{DynPCA($DG$, $X$, $U$, $r$, $m$, $n$)}{
		$G \leftarrow \FuncCall{ConstructGraph}{$DG$, $X$, $U$, $r$, $m$, $n$}$\;
		Run the Ford Fulkerson algorithm on the network flow graph $G$\;
		\Return{False}
	}
\end{algorithm}\-\\
Complexity is something










\subsection{
	Present the analysis on the correctness of your algorithm.
}

\subsubsection{
	Show that a solution to the original problem will result in flows (i.e. satisfies
	the conservation and capacity conditions) in the network flow graph $G$.
}
\begin{proof}
	Suppose there exists an assignment of ads to users such that all advertisers are satisfied.
	Consider the solution where each advertiser $a_i$, will have $r_i$ ads shown to one
	demographic group, $dg_k \in X_i$.
	We will show that we can obtain an $s-t$ flow from such assignment.

	Let there be $r_i$ number of user nodes, $u_j$, that belong to demographic group $dg_k$ for each
	advertiser $a_i$. For each $u_j$ and its advertiser $a_i$, consider the flow that sends one unit
	along each path of $s \rightarrow u_j \rightarrow dg_k \rightarrow a_i \rightarrow t$.
	Let $f(e)=1$ for each $s \rightarrow u_j$ and $u_j \rightarrow dg_k$ edge.
	By definition, conservation condition holds for all $u_j$.
	The capacity condition holds for all $s \rightarrow u_j$ and $u_j \rightarrow dg_k$ edges
	because the capacities of those edges is $1$.

	We know that $f^{in}(dg_k)$ will be equal to the sum of $r_i$ where advertiser $a_i$'s demographic group
	was chosen to be $dg_k$. Let $f(e)=r_i$ for each $dg_k \rightarrow a_i$.
	Hence, conservation condition holds for all $dg_k$.
	The capacity condition holds for all $dg_k \rightarrow a_i$ because
	because the capacities of those edges is $r_i$.

	Let $f(e)=r_i$ for each $a_i \rightarrow t$. Hence, conservation condition holds for all $a_i$.
	The capacity condition holds for all $a_i \rightarrow t$ because
	because the capacities of those edges is $r_i$.

	Therefore, there exists an assignment of ads to users such that all advertisers are satisfied
	which results in a flow network. If all advertisers are satisfied, the total $s \rightarrow t$ flow
	will be $\sum_{i=1}^m r_i$. Otherwise, it will be less than the previous sum with flows less than $r_i$
	on edges $a_i \rightarrow t$.
\end{proof}


\subsubsection{
	Show that the solution to the network flow problem will give the solution for
	the original problem.
}


\begin{proof}
	Suppose we have a solution with the $s \rightarrow t$ flow being $\sum_{i=1}^m r_i$.
	This means that $f(e) = r_i$ for at all edges $a_i \rightarrow t$ as the this is the only 
	way to get total flow of $\sum_{i=1}^m r_i$. Consequently, this means we have identified 
	$r_i$ users for each $a_i$ advertiser.  Thus, all advertisers will be satisfied. 

	If the algorithm gives us a maximum $s \rightarrow t$ flow that is less than $\sum_{i=1}^m r_i$, 
	it means $f(e) < r_i$ for at least one edge $a_i \rightarrow t$. 
	Thus, some advertiser will not have the number of ads shown to users they requested. 
	That is why in this case we can claim that there doesn't exist enough users such that 
	all advertisers are satisfied.
\end{proof}




%7.26
%https://github.com/apizzuto/CS577/blob/master/Assignment7.pdf





























\iffalse
	If all advertisers are satisfied that means $f(e) = r_i$ for each edge $(a_i,t)$.
	To satisfy the conservation condition, let $f^{in}(a_i) = r_i$.
	The capacity condition holds for edges $(a_i,t)$ because we defined the capacity to $r_i$ in our graph.

	To satisfy the conservation condition for the demographic nodes, let these nodes have a flow
	value of $f^{in}(dg_i) = r_i$.
	The capacity condition holds for edges $(dg_i,a_i)$ because we set defined the capacity to $r_i$ in our graph.

	Since we assumed that these exists an assignment of ads to users such that all advertisers are
	satisfied, there must exist at least $r_i$ users for each advertiser $i$ such that they belong in at least one
	demographic group that the advertiser is targeting, i.e. belongs to $X_i$.


	\begin{enumerate}[label=\alph*.]
		\item{
		      \textbf{Capacity Conditions}\\
		      yes
		      }
		\item{
		      \textbf{Conservation Conditions}
		      }
	\end{enumerate}
\fi



\iffalse
	The greedy strategy is to first sort the programmers in ascending order of productivity.
	Then, we pair the first two programmers, then the next two, etc. We sum up all the
	slower programmer in each pair, which will be our maximum sum of productivity.
	\begin{algorithm}
		\KwData{A list $gamer$ of even size $n$, containing the productivity level of each programmer}
		\KwResult{The maximum sum of productivity for pair programming}
		\Fn{maxProd($gamer$)}{
			sortedGamer $\leftarrow$ Sort $gamer$ in ascending order of productivity\\
			totalProd $\leftarrow$ 0\\
			\For{int i = 0; i < n; i+=2}{
				totalProd += sortedGamer[i]
			}
			\Return{\text{\normalfont totalProd}}
		}
	\end{algorithm}\\
	The time complexity of maxProd is $O(n\log n)$
	\begin{proof}
		We first sort the list gamer of size $n$. Using an efficient sorting algorithm such as
		merge sort, this will take $O(n\log n)$ time. Then, we sum up every other element
		in the list, which takes $O(n)$ time. The rest of the computations take constant time.
		Hence, the total time complexity is $O(n\log n + n) = O(n\log n)$
	\end{proof}
	\subsection{
		Prove that this greedy strategy indeed generates the maximum sum of
		productivity.
	}
	We will use a “Greedy Stays Ahead” argument to prove this greedy strategy.
	\subsubsection{
		Define Your Solution
	}
	Let $A=\{a_1, a_2, \cdots, a_{n/2}\}$ denote the pairs containing the productivity values of two programmers
	that our algorithm will generate, i.e. $a_i = (p_\alpha, p_\beta)$ where $p_\alpha$ and $p_\beta$ are the
	productivity values of $\alpha$ and $\beta$th lowest productive programmer in this $i$th pair respectively.
	Let $O = \{o_1, o_2, \cdots, o_{n/2}\}$ denote the pairs containing the productivity values of two programmers
	that an optimal algorithm will generate. Let $O$ be ordered in ascending productivity, i.e. if $i>j$,
	the productivity of pair $o_i$ will be equal to or higher than pair $o_j$.
	\subsubsection{
		Define Your Measure
	}
	For our algorithm, let $\delta(a_1), \cdots, \delta(a_{n/2})$ denote the total productivity of pairs
	from $a_1$ to $a_i$. For example, $\delta(a_3)$ will be the sum of the productivity (the
	lower productivity between the two programmers) of pairs $a_1$, $a_2$, and $a_3$.
	Formally, we can express this function as
	$$\delta(a_i) = \sum_{j=1}^i \min(a_j)$$
	Similiary for the optimal algorithm, the $\delta(o_1), \cdots, \delta(o_{n/2})$ denote
	the total productivity of pairs from $o_1$ to $o_i$.
	\subsubsection{
		Prove Greedy Stays Ahead
	}
	We show by induction that our greedy stays ahead.
	\begin{proof}
		Let $P(i)$ be the predicate, "$\delta(a_i) \geq \delta(o_i)$"
		We define $i \in \mathbb{N}^+$. \\
		\textbf{Base Case:} When $i = 1$, we know that $a_1$ contains the lowest productivity programmer
		because we paired up the two lowest productivity programmers in our algorithm. We also know that
		$o_1$ contains the lowest productivity programmer because we ordered $O$ in ascending productivity.
		The least productive pair must contain the lowest productivity programmer because the
		productivity any pair containing the lowest productivity programmer will the productivity value of the
		lowest productivity programmer.
		Hence, the productivity of pair $a_1$ will be the value of lowest productivity programmer, and
		similarly, the productivity of pair $o_1$ will be the value of lowest productivity programmer.
		Thus, $\delta(a_1) \geq \delta(o_1)$ and $P(1)$ holds.\\
		\textbf{Inductive step:} Suppose $P(k-1)$ holds. We show that $P(k)$ holds.
		By our algorithm, we know that pair $a_k$ contains the $(2k-1)$th lowest productive
		programmer and $a_k$'s productivity value will be the productivity value of the
		$(2k-1)$th lowest productive programmer, i.e. $\min(a_k) = p_{2k-1}$.
		We claim that we can bound the productivity value of pair $o_k$ by
		%$p_k \leq 
		$\min(o_k) \leq p_{2k-1}$. We know that since $O$ is ordered
		in ascending productivity, the productivity value of pair $o_k$ must be equal or greater
		to the pairs that came before it. There are $2k-2$ programmers that come before pair
		$o_k$. This means that at most, there are $2k-2$ programmers with lower or equal productivity value
		than productivity value of pair $o_k$ from the pairs behind $o_k$.
		If we include the programmer that determines the productivity value of pair $o_k$,
		we have $2k-1$ programmers with lower or equal productivity value
		than productivity value of pair $o_k$. It follows from the pigeonhole principle
		that $\min(o_k) \leq p_{2k-1}$ because if $\min(o_k) \geq p_{2k}$ then
		there would exist some programmer with productivity value equal or
		less than $p_{2k-1}$ that will not belong in the pairs behind $o_k$ but
		rather ahead of $o_k$, which would be a contradiction because $O$ is
		ordered, i.e. $p_{2k}$ will appear before $p_{2k-1}$.
		Using this bound we know that $\min(a_k)\geq \min(o_k)$ and by our induction
		hypothesis we know that $\delta(a_{k-1}) \geq \delta(o_{k-1})$. It follows that,
		\begin{align*}
			\delta(a_k) & = \delta(a_{k-1}) + \min(a_k)    \\
			            & \geq \delta(o_{k-1}) + \min(o_k) \\
			            & \geq \delta(o_k)
		\end{align*}
		$P(k)$ holds as desired. Therefore by induction, $\delta(a_i) \geq \delta(o_i)$ for all $i \in \mathbb{N}^+$.
	\end{proof}


	\subsubsection{
		Prove Optimality
	}
	Since both $O$ and $A$ have the same number of pairs, $n/2$, it follows from our proof
	from 1.2.3 that $\delta(a_{n/2}) \geq \delta(o_{n/2})$. Therefore, our algorithm is
	optimal because
	the total productivity of $A$ is equal or greater than the total productivity of
	$O$.

	\section{
	  Give an algorithm that increases the lengths of certain edges so that
	  the resulting tree has zero skew and the total edge length is as small as
	  possible.
	 }

	\subsection{
		Describe a greedy strategy and write it in the algorithm format. Also
		analyze the computing complexity of the algorithm.
	}
	This algorithm recursively makes both subtrees of a vertex zero skew and then
	computes the correct cost to add to either the left or right edge to make the
	entire tree zero skew. We recurse all the way down to the leaves and notice that
	subtrees where its root is a leaf is already zero skew so we return $0$.
	On the following layers up, we consider the edge length from the current node $v$ and
	its left and right child, $l$ and $r$, and the time it takes $l$ to go its leaves and
	$r$ to go its leaves. We denote the time it takes $l$ and $r$ to go its leaves, $\delta_l$
	and $\delta_r$ respectively. We check whether $\delta_l + \ell_{v,l}$ or $\delta_r + \ell_{v,r}$
	is greater and adjust $\ell_{v,l}$ or $\ell_{v,r}$ accordingly to make the subtree zero skew.
	We continue this process until the entire tree is zero skew.
	\begin{algorithm}
		\KwData{$T = (V,E,\ell)$, a complete balanced binary tree with an associated edge length $\ell$\\
			\qquad \hspace{0.5em} $v \in V$, a vertex for a subtree to make zero skew }
		\KwResult{Length from root to leaf (zero skew value); a tree has zero skew and the total edge length is as small as	possible}
		\Fn{timingCircuit($v$)}{
			\If{$v$ is a leaf}{
				\Return{0}
			}
			$\delta_l = $ timingCircuit($l$)\\
			$\delta_r = $ timingCircuit($r$)\\
			%$\ell_{L} =$ edge length of $v$ to $L$ \\
			%$\ell_{R} =$ edge length of $v$ to $R$ \\
			\# Where $\ell_{(a,b)}$ is the associated length of edge $(a,b) \in E$\\
			\If{$\delta_l + \ell_{(v,l)} > \delta_r + \ell_{(v,r)}$}{\-\\
				Increment $\ell_{(v,r)}$ by $(\delta_l + \ell_{(v,l)}) - (\delta_r + \ell_{(v,r)})$
			}
			\ElseIf{$\delta_r + \ell_{(v,r)} > \delta_l + \ell_{(v,l)}$}{\-\\
				Increment $\ell_{(v,l)}$ by $(\delta_r + \ell_{(v,r)}) - (\delta_l + \ell_{(v,l)})$
			}
			\Return{$\delta_r + \ell_{(v,r)}$}
		}
	\end{algorithm}\-\\
	The time complexity of timingCircuit is $\Theta(n)$.
	\begin{proof}
		Each recursive call in our algorithm halves the input size and we have two
		recursive calls. The rest of the computations take constant time.
		We get a recurrence relationship of $T(n) = 2T(n/2) + n^0$
		which is $\Theta(n)$ by the master theorem.
	\end{proof}
	\subsection{
		Prove that this greedy strategy indeed generates the optimal solution
	}
	\begin{lemma}
		The algorithm timingCircuit will always generate a zero skew tree.
	\end{lemma}
	\begin{proof}
		We show by strong induction that timingCircuit will always generate a zero skew tree.
		Let $P(n)$ be the predicate "timingCircuit will generate a zero skew tree that has $n$ leaves".
		We define $n \in \mathbb{N}^+$. \\
		\textbf{Base Case:} When $n = 1$, timingCircuit returns $0$. It is trivially true
		that a tree with a single node will always have zero skew. Hence $P(1)$ holds.\\
		\textbf{Inductive step:} Suppose for all $1 \leq n \leq k$, $P(n)$ holds. We show that $P(k+1)$ holds.
		We know that the subtrees generated by the children of $v$, $l$ and $r$, will have strictly less
		leaves than $k+1$. It follows by our strong inductive hypothesis, that timingCircuit($l$) and timingCircuit($r$)
		will correctly generate a zero skew subtrees for the subtrees that have $l$ and $r$ has its root,
		and return the distance from $l$ to its leaves, $\delta_r$, and $r$ to its leaves, $\delta_l$.
		Since the two subtrees generated by the children $v$ are zero skew, all we need to do so that
		the entire tree is zero skew is to
		modify the edge length between $(v,l)$ and $(v,r)$ such that
		$\delta_r + \ell_{(v,r)} = \delta_l + \ell_{(v,l)}$, i.e. both subtrees have same zero skew
		if we start from $v$. This is exactly what we do in the if and else if statement in our algorithm.
		Hence, timingCircuit generates a zero skew tree that has $k+1$ leaves and $P(k+1)$ holds.
		Therefore by strong induction, timingCircuit will always generate a zero skew tree.
	\end{proof}

	We define terms for the following theorem.
	Let $T$ be the original tree and let $\ell$ be its associated edge length.
	Let $v$ be the root of $T$ and let $l$ and $r$ be the left and right child of $v$ respectively.
	Let $T_\alpha$ be the tree generated by timingCircuit. Let $T_\phi$ be an
	optimal tree, i.e. a zero skew tree such that the total edge length is as small as possible.
	Let the left and right subtree of $T_\alpha$ be $L_\alpha$, $R_\alpha$.
	Similiarly, define $L_\phi$, $R_\phi$.
	Let $\ell^\alpha$ and $\ell^\phi$ and the associated edge length of $T_\alpha$ and $T_\phi$ respectively.

	\iffalse
		\begin{lemma}
			If $L_\alpha = L_\phi$ and $R_\alpha = R_\phi$,	then $\ell^\alpha_{(v,l)} \leq \ell^\phi_{(v,l)}$ and
			$\ell^\alpha_{(v,r)} \leq \ell^\phi_{(v,r)}$.
		\end{lemma}
		\begin{proof}
			Consider the case when $\delta_l + \ell_{(v,l)} > \delta_r + \ell_{(v,r)}$.
			We show $\ell^\alpha_{(v,l)} \leq \ell^\phi_{(v,l)}$ and
			$\ell^\alpha_{(v,r)} \leq \ell^\phi_{(v,r)}$.
			Suppose for the sake of contradiction, $\ell^\alpha_{(v,l)} > \ell^\phi_{(v,l)}$.

		\end{proof}
	\fi
	\begin{theorem}
		The algorithm timingCircuit will always generate a zero skew tree such that the
		total edge length is as small as possible.
	\end{theorem}
	\begin{proof}
		From lemma 2.1, we know that timingCircuit will always generate a zero skew tree.
		It is sufficient to show that timingCircuit will minimize total edge length when
		generating this tree. %We show by an exchange argument that timingCircuit is optimal.
		%Suppose $T_\alpha \neq T_\phi$, where T_\phi. There must exist an edge $(a,b) \in E$ 
		%Suppose $T_\alpha$ is not an optimal solution, i.e. total edge length of $T_\phi$ 
		%is strictly less than total edge length of $T_\alpha$.
		We continue with an exchange argument.
		Suppose the optimal solution, $T_\phi$, does not use the edge weights generated by our algorithm, $T_\alpha$,
		i.e. total edge length of $T_\phi$ is strictly less than total edge length of $T_\alpha$.
		This means there exists an edge $(a,b)$ such that $\ell^\alpha_{(a,b)} > \ell^\phi_{(a,b)}$.
		Fix $(a,b)$ such that it is the closet edge from the leaves.
		%We know that to total edge length of $T_\phi$ increased by at least $\ell^\phi_{(a,b)} - \ell^\alpha_{(a,b)}$
		%compared to $T$. 
		Let $U$ be an induced subgraph of $T_\phi$ such that it only contains edges
		which its weight has not been increased compared to $T$. Let the connected component
		containing $b$ in $U$ be $X$.
		Define $Y$ to be the set of edges such that one vertex is in $X$ and one vertex is in $E \setminus X$,
		where $E$ is the set of all edges in $T$. Let $\zeta$ to be the smallest
		change on edge length between $T_\phi$ and $T$ in $E$, or more formally
		$\zeta = \min\{\ell^\phi_{(a,b)} - \ell_{(a,b)}  \mid (a,b) \in E \} $.
		Notice we can construct a new tree, $T_o$, from $T_\alpha$ where we reduce all edges by $\zeta$
		in $E$ and increase the edge of $(a,b)$ by $\zeta$. $T_o$ will still be zero skew by construction
		and its total edge weight will be smaller or equal than $T_\phi$, making it optimal.
		Without loss of generality, we can perform this process to all edges $(a,b)$ where
		$\ell^\alpha_{(a,b)} > \ell^\phi_{(a,b)}$.
		At the end of the process, we will have edge weights produced by our algorithm,
		such that it is no greater than that the edge weights of $T_\phi$ we considered.
		Therefore, the edge weights produced by our algorithm must also be optimal.

		%\ell^\alpha_{(a,b)} > \ell^\phi_{(a,b)}

		%This means that the edge length on the 
		%original tree, $\ell_{(a,b)}$, must of increased by at least $\ell^\phi_{(a,b)} - \ell^\alpha_{(a,b)}$ .
	\end{proof}








\fi
\end{document}

