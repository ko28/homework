\documentclass[11pt]{scrartcl}
\usepackage[sexy]{../../evan}
\usepackage{cmbright}
\usepackage{cancel}
\usepackage[T1]{fontenc}
%\usepackage{enumerate}
\usepackage[shortlabels]{enumitem}
\usepackage[utf8]{inputenc}
\usepackage[margin=1in]{geometry}
%\usepackage[pdfborder={0 0 0},colorlinks=true,citecolor=red{}]{hyperref}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{setspace}
\usepackage{systeme}

\makeatletter
\newenvironment{Dequation}
  {%
  \def\tagform@##1{%
    \maketag@@@{\makebox[0pt][r]{(\ignorespaces##1\unskip\@@italiccorr)}}}%
  \ignorespaces
  }
  {%
  \def\tagform@##1{\maketag@@@{(\ignorespaces##1\unskip\@@italiccorr)}}%
  \ignorespacesafterend
  }
\makeatother

\title{Math 341: Homework 6}
\author{Daniel Ko}
\date{Spring 2020}

\begin{document}
\maketitle

\section{A}
Find the rank of the following matrices.

\begin{enumerate}[label=\alph*.]
	\item{
			2
			show work later
	}
	\item{
			3
		}
	\item{
			2
	}
	\item{
			1
		}
	\item{
			3
		}
	\item{
			3
	}
	\item{
			1
		}
\end{enumerate}

\section{B}
Prove that any elementary row [column] operation of type 1 can be obtained by a succession of three elementary
row [column] operations of type 3 followed by one elementary row [column] operation of type 2
\begin{proof}
Row operation type 1 on row $i$ and row $j$ can be done by the following:
\begin{enumerate}[label=\arabic*.]
	\item{
		Row operation type 3: Add $-1$ times row $i$ to row $j$ 
	}
	\item{
		Row operation type 3: Add row $j$ to row $i$
	}
	\item{
		Row operation type 3: Add $-1$ times row $i$ to row $j$
	}
	\item{
		Row operation type 2: Multiply row $j$ by $-1$
	}
\end{enumerate}
Without loss of generality, same could be done for a elementary column operation of type 1.
\end{proof}

\section{C}
Let A be an $mxn$ matrix. Prove that there exists a sequence of elementary row operations of types 1 and 3 that
transforms A into an upper triangular matrix.
\begin{proof}
	Iterate through each column, let this variable be c. If $A_{c,c}$ equals 0, go through all the elements in that column below
	$A_{c,c}$ and find the first non zero element. Perform a type 1 row operation on row $c$ and the row the non zero element
	was found. If there is no non zero element, do nothing and go to the next column. \\
	\-\\
	If $A_{c,c}$ does not equal 0, perform a type 3 row operation on each row below $A_{c,c}$. Multiply 
	$- \frac{A_{r,c}}{A_{c,c}}$ by the $c$th row to the $r$th row, where $r$ is every row below $c$.  
\end{proof}

\section{D}
Complete the proof of the corollary to Theorem 3.4 by showing that elementary column operations preserve rank.
\begin{proof}
	If B is obtained from a matrix A by an elementary column operation,
	then there exists an elementary matrix E such that B = AE. By Theorem 3.2, 
	E is invertible, and hence rank(B) = rank(A) by Theorem 3.4. 
\end{proof}
	

\section{E}
Let $B$ and $B'$ is an $mxn$ matrix submatrix of B. Prove that rank($B$) = $r$, then rank($B'$) = $r - 1$
\begin{proof}
Consider the matrix 
\[
M=
\left[\begin{array}{@{}c|ccc@{}}
0 & & & \\
\vdots & & B' & \\
0 & & &
\end{array}\right]	
\]
$M$ has the same number of linearly independent columns to that of $B'$, so rank($M$) = rank($B'$)
Now consider the matrix below.
\[
B=
\left[\begin{array}{@{}c|ccc@{}}
1 & 0 &\cdots &0 \\ \hline
\vdots & & B' & \\
0 & & &
\end{array}\right]	
\]
$B$ has one more linearly independent row to that of M.\\ Then rank($B$) = rank($M$) + 1 = rank($B'$) + 1.\\
Therefore, if rank($B$) = r, then rank($M$) = rank($B'$) = r - 1.
\end{proof}
	

\section{F}
Let $B'$ and $D'$ be $mxn$ matrices, and let $B$ and $D$ be $(m + 1)x(n + 1)$ matrices respectively. 
Prove that if $B'$ can be transformed into $D'$ by an elementary row [column] operation, then $B$ can be transformed
into $D$ by an elementary row [column] operation.
\begin{proof}
If $B'$ can be tranformed into $D'$ by elementary row operations, there must exist an elementary matrix $E$ 
such that $D'=EB'$ by theorem 3.1. Now consider the matrix below.
\[
A=
\left[\begin{array}{@{}c|ccc@{}}
1 & 0 &\cdots &0 \\ \hline
\vdots & & E & \\
0 & & &
\end{array}\right]	
\]
A is also an elementary matrix, 
We can observe that $D = AB$, thus $B$ can be tranformed to $D$ by elementary row operations.
Without loss of generality, there exist a matrix $F$ such that $D' = B'F$ where $F$ is the elementary column matrix.
So, $D = BF$ where $B$ is like the $A$ matrix but with $F$ instead of $E$. Therefore. $B$ can be tranformed
to $D$ by elementary column operations. 
\end{proof}

\section{G}

\begin{enumerate}[label=\alph*.]
	\item{
		Find a $5x5$ matrix $M$ with rank 2 such that $AM=O$ where $O$ is the $4x5$ zero matrix.
		\begin{proof}
			By solving $Ax=0$, we get this system of equation:\\
			\systeme{
				x_1 - x_3 +  2x_4 + x_5 = 0,
				-x_1 + x_2 + 3x_3 - x_4 = 0,
				-2x_1 + x_2 + 4x_3 - x_4 + 3x_5 = 0,
				3x_1 - x_2 - 5x_3 + x_4 - 6x_5 = 0}\\
			Solving this system of equations by computing reduced row echelon form, 
			we get that $x_1, x_2, x_4$ are the pivot variables and $x_3, x_5$ are the 
			free variables. So solutions are in the form 
			$(x_3+3x_5,-2x_3+x_5, x_3, -2x_5,x_5)$. From this, we are able to 
			construct a basis for Ax=0, $\{(1,-2,1,0,0),(3,1,0,-2,1)\}$.
			Define   
			\[			
				M=
				\left[\begin{array}{ccccc}
				1 &3 & 0 & 0 &0 \\ 
				-2 &1 & 0 & 0 &0 \\ 
				1 &0 & 0 & 0 &0 \\ 
				0 &-2 & 0 & 0 &0 \\ 
				0 &1 & 0 & 0 &0 
				\end{array}\right]	
			\]
			It is obvious that this matrix has rank 2 and is $5x5$. Because the column is a basis for $Ax=0$, the resulting matrix will be $O$.
		\end{proof}
	}
	\item{
		Suppose that $B$ is a $5x5$ matrix such that $AB=O$. Prove that rank$(B) \leq 2$
		\begin{proof}
			Since $AB=O$, we know that the columns of $B$ is a solution to $Ax=0$, which is a subset of the nullspace of $L_A$.
			From the rank nullity theorem, we know that $\text{dim}(\mathbb{F}^5) = \text{rank}(L_A) + \text{nullity}(L_A)$.\\
			$\text{nullity}(L_A) = \text{dim}(\mathbb{F}^5) - \text{rank}(L_A) = 5 - 3 = 2$. So, rank($B$) cannot be greater than 2. 
			Therefore, rank$(B) \leq 2$.
		\end{proof}
	}
\end{enumerate}

\section{H} 
For each of the following linear transformations $T$, determine whether $T$ is invertible, and compute $T^{-1}$ if it exists.

\-\\
Let $\alpha$ be the standard basis for the domain and $\gamma$ be the standard basis for the codomain for 
each of these tranformations below. For each of these problems, we can use theorem 2.18 and
its corollaries to determine if the transformations are invertible, namely we need to show 
that $[T]_{\alpha}^{\gamma}$ is invertible.
\begin{enumerate}[label=\alph*.]
	\item{
	$T : P_2(R) \rightarrow P_2(R)$ defined by $T(f(x)) = f''(x) + 2f'(x) - f(x)$
	\begin{proof}
	\begin{align*}
	[T]_{\alpha}^{\gamma} & = [[T(1)]_{\gamma}, [T(x)]_{\gamma}, [T(x^2)]_{\gamma}]\\
	& = [[-1]_{\gamma}, [-x + 2]_{\gamma}, [-x^2 + 4x + 2]_{\gamma}]\\
	& = \begin{bmatrix}
		-1 & 2 & 2\\
		0 & -1 & 4 \\ 
		0 & 0 & -1 \\
	\end{bmatrix}
	\end{align*}
	To see if the matrix above is invertible, we can use an agumented matrix 
	$([T]_{\alpha}^{\gamma}|I_3)$ and apply elementary row operations to tranform it 
	into the form of $(I_3|[T^{-1}]_{\alpha}^{\gamma})$.
	\begin{align*}
	([T]_{\alpha}^{\gamma}|I_3)=
	\left[\begin{array}{ccc|ccc}
	-1 & 2 & 2 & 1 & 0 & 0 \\ 
	0 & -1 & 4 & 0 & 1 & 0 \\ 
	0 & 0 & -1 & 0 & 0 & 1 \\ 
	\end{array}\right]\\
	r_1 \leftarrow -r_1,\quad r_2 \leftarrow -r_2, \quad r_3 \leftarrow -r_3\\
	\left[\begin{array}{ccc|ccc}
	1 & 2 & 2 & -1 & 0 & 0 \\ 
	0 & 1 & 4 & 0 & -1 & 0 \\ 
	0 & 0 & 1 & 0 & 0 & -1 \\ 
	\end{array}\right]\\
	r_1 \leftarrow 2r_2 + r_1\\
	\left[\begin{array}{ccc|ccc}
	1 & 0 & -10 & -1 & -2 & 0 \\ 
	0 & 1 & -4 & 0 & -1 & 0 \\ 
	0 & 0 & 1 & 0 & 0 & -1 \\ 
	\end{array}\right]\\
	r_1 \leftarrow 10r_3 + r_1, \quad r_2 \leftarrow 4r_3 + r_2\\
	(I_3|[T^-1]_{\alpha}^{\gamma})=
	\left[\begin{array}{ccc|ccc}
	1 & 0 & 0 & -1 & -2 & -10 \\ 
	0 & 1 & 0 & 0 & -1 & -4 \\ 
	0 & 0 & 1 & 0 & 0 & -1 \\ 
	\end{array}\right]\\
	\end{align*}	
	Therefore, the inverse of $T$ exists and is \\$T^{-1}(a_0 + a_1x + a_2x^2) 
	=-a_0 -2a_2 -10a_2 + (-a_1 - 4a_2)x -a_2x^2$
	\end{proof}
	}

	\item{
	$T : P_2(R) \rightarrow P_2(R)$ defined by $T(f(x)) = (x + 1)f'(x)$
	\begin{proof}
	\-\\
	Similiar to (a), we will calculate $[T]_{\alpha}^{\gamma}$.
	\[
	[T]_{\alpha}^{\gamma} = 
	\begin{bmatrix}
		0 & 1 & 0\\
		0 & 1 & 2\\ 
		0 & 0 & 2\\
	\end{bmatrix}
	\]
	Notice that the rank of this matrix is 2, which means rank($[T]_{\alpha}^{\gamma}$) $\neq 3$.
	Therefore, there is no inverse for this matrix by the remark in chapter 3.2,
	"an $nxn$ matrix is invertible if and only if its rank is $n$".
	\end{proof}
	}

	\item{
	$T:R^3 \rightarrow R^3$ defined by $T(a_1, a_2, a_3) =
	(a_1 + 2a_2 + a_3, -a_1 + a_2 + 2a_3, a_1 + a_3)$ 
	\begin{proof}
	\-\\
	Similiar to (a), we will calculate $[T]_{\alpha}^{\gamma}$.
	\[
	[T]_{\alpha}^{\gamma} = 
	\begin{bmatrix}
		1 & 2 & 1\\
		-1 & 1 & 2\\
		1 & 0 & 1 \\
	\end{bmatrix}
	\]
	We can calculate the inverse of $T$ by following the same steps we did in (a).
	\[
	[T^{-1}]_{\alpha}^{\gamma} = 
	\begin{bmatrix}
		\frac16 & -\frac13 & \frac12\\
		\frac12 & 0 & -\frac12\\
		-\frac16 & \frac13 & \frac12 \\
	\end{bmatrix}
	\]
	Therefore, the inverse of $T$ exists and is \\$T^{-1}(a_1, a_2, a_3) 
	=(\frac16a_1 -\frac13a_2 + \frac12a_3,\frac12a_1 -\frac12a_3,
	-\frac16a_1 + \frac13a_2 + \frac12a_3)$
	\end{proof}
	}

	\item{
		$T:R^3 \rightarrow P_2(R)$ defined by $T(a_1, a_2, a_3) =
		(a_1 + a_2 + a_3) + (a_1 - a_2 + a_3)x + a_1x^2$ 
		\begin{proof}
		\-\\
		Similiar to (a), we will calculate $[T]_{\alpha}^{\gamma}$.
		\[
		[T]_{\alpha}^{\gamma} = 
		\begin{bmatrix}
			1 & 1 & 1\\
			1 & -1 & 1\\
			1 & 0 & 0 \\
		\end{bmatrix}
		\]
		We can calculate the inverse of $T$ by following the same steps we did in (a).
		\[
		[T^{-1}]_{\alpha}^{\gamma} = 
		\begin{bmatrix}
			0 & 0 & 1\\
			\frac12 & -\frac12 & 0\\
			\frac12 & \frac12 & -1\\
		\end{bmatrix}
		\]
		Therefore, the inverse of $T$ exists and is \\$T^{-1}(a_1 + a_2x + a_3x^2) 
		=(a_3, \frac12a_1 - \frac12a_2, \frac12a_1 + \frac12a_2 -a_3)$
		\end{proof}
	
	}

	\item{
		$T:P_2(R) \rightarrow R^3$ defined by $T(f(x)) = (f(-1),f(0),f(1))$
		\begin{proof}
		\-\\
		Similiar to (a), we will calculate $[T]_{\alpha}^{\gamma}$.
		\[
		[T]_{\alpha}^{\gamma} = 
		\begin{bmatrix}
			1 & -1 & 1\\
			1 & 0 & 0\\
			1 & 1 & 1 \\
		\end{bmatrix}
		\]
		We can calculate the inverse of $T$ by following the same steps we did in (a).
		\[
		[T^{-1}]_{\alpha}^{\gamma} = 
		\begin{bmatrix}
			0 & 1 & 0\\
			-\frac12 & 0 & \frac12\\
			\frac12 & -1 & \frac12\\
		\end{bmatrix}
		\]
		Therefore, the inverse of $T$ exists and is \\$T^{-1}(a_1, a_2, a_3) 
		=a_2 + (-\frac12 a_1 + \frac12 a_3)x + (\frac12a_1 -a_2 + \frac12a_3)x^2$
		\end{proof}
		}

		\item{
		$T:M_{2x2}(R) \rightarrow R^4$ defined by $T(A) = (tr(A), tr(A^t), tr(EA), tr(AE))$
		where 
		$E = 
		\begin{bmatrix}
		0 & 1 \\
		1 & 0 \\ 
		\end{bmatrix}
		$
		\begin{proof}
		\-\\
		Similiar to (a), we will calculate $[T]_{\alpha}^{\gamma}$.
		\[
		[T]_{\alpha}^{\gamma} = 
		\begin{bmatrix}
			1 & 0 & 0 & 1\\
			1 & 0 & 0 & 1\\
			0 & 1 & 1 & 0\\
			0 & 1 & 1 & 0\\
		\end{bmatrix}
		\]
		Notice that the rank of this matrix is 2, which means rank($[T]_{\alpha}^{\gamma}$) $\neq 4$.
		Therefore, there is no inverse for this matrix by the remark in chapter 3.2,
		"an $nxn$ matrix is invertible if and only if its rank is $n$".
		\end{proof}
		}
\end{enumerate}



\section{I} 
Express the invertible matrix
$
\begin{bmatrix}
1 & 2 & 1\\
1 & 0 & 1 \\ 
1 & 1 & 2 \\ 
\end{bmatrix}
$
as a product of elementary matrices
\begin{proof}
Theorem 3.6 states that there exists
 Theorem 3.6
 \begin{align*}
	(M|I)=
	\left[\begin{array}{ccc|ccc}
	1 & 2 & 1 & 1 & 0 & 0 \\ 
	1 & 0 & 1 & 0 & 1 & 0 \\ 
	1 & 1 & 2 & 0 & 0 & 1 \\ 
	\end{array}\right]\\
	(M_1|E_1)=
	\left[\begin{array}{ccc|ccc}
	1 & 2 & 1 & 1 & 0 & 0 \\ 
	1 & 0 & 1 & 0 & 1 & 0 \\ 
	0 & 1 & 1 & 0 & -1 & 1 \\ 
	\end{array}\right]
\end{align*}
\end{proof}

\section{J}
Suppose that $A$ and $B$ are matrices having $n$ rows. Prove that $M(A|B) = (MA|MB)$ for any $mxn$ matrix
\begin{proof}
Let $A$ have $a$ number of columns and $B$ have $b$ number of columns. \\
Notice for $1 \leq j \leq a$:
$(M(A|B))_{i,j} = \sum_{k=1}^{n} M_{i,k}A_{k,j} = (MA)_{i,j} = (MA|MB)_{i,j}$\\
Similarily for $a < j \leq a + b$:
$(M(A|B))_{i,j} = \sum_{k=1}^{n} M_{i,k}B_{k,j} = (MB)_{i,j} = (MA|MB)_{i,j}$\\
Therefore, $M(A|B) = (MA|MB)$ for any $mxn$ matrix.
\end{proof}
\end{document}