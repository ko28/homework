\documentclass[11pt]{scrartcl}
\usepackage[sexy]{../../evan}
\usepackage{cmbright}
\usepackage{cancel}
\usepackage[T1]{fontenc}
%\usepackage{enumerate}
\usepackage[shortlabels]{enumitem}
\usepackage[utf8]{inputenc}
\usepackage[margin=1in]{geometry}
%\usepackage[pdfborder={0 0 0},colorlinks=true,citecolor=red{}]{hyperref}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{setspace}

\makeatletter
\newenvironment{Dequation}
  {%
  \def\tagform@##1{%
    \maketag@@@{\makebox[0pt][r]{(\ignorespaces##1\unskip\@@italiccorr)}}}%
  \ignorespaces
  }
  {%
  \def\tagform@##1{\maketag@@@{(\ignorespaces##1\unskip\@@italiccorr)}}%
  \ignorespacesafterend
  }
\makeatother

\title{Math 341: Homework 4}
\author{Daniel Ko}
\date{Spring 2020}

\begin{document}
\maketitle

\section{A}
Let V be a vector space having dimension n, and let S be a subset of V that generates V.

\begin{enumerate}[label=\alph*.]
	\item{
			Prove that there is a subset of S that is a basis for V. (Be careful not to assume that S is finite).
			\begin{proof}
			\-\\
			Since V is finite dimensional, there exists a basis for V.\\
			$B = \{v_1, v_2, \cdots, v_n\}$\\
			Any $v \in B$ can be expressed as a linear combination of S because span(S) = V.\\
			%$v_i = \{s_1, s_2, \cdots, s_m\}$
			Let the subset of S that generates $v_i$ be $S_i$\\
			$v_i = \sum_{j=1}^{m^k} a_j^k s_j^k$ where $a\in F$ and $s \in S_i$\\
			The span of the union of the sets that generates v, $\text{span(} \bigcup_{i=1}^{n}S_i \text{)} = V$\\ 
			Corollary 2(a) of Theorem 1.10 states that a generating set for V that contains exactly n vectors is a basis for V.
			The set above, which is a subset of S, contains exactly n vectors and generates V. Therefore, there is subset of S that is a basis for V. 
			\end{proof}

	}
	\item{
			Prove that S contains at least n vectors.
			\begin{proof}
			\-\\
			From (a) we know there is a subset of S that forms a basis. Since that subset contains n vectors, S must contain n or more vectors. 
			\end{proof}
		}
\end{enumerate}

\section{B}
Let $f(x)$ be a polynomial of degree n in $P_n(R)$. Prove that for any $g(x) \in P_n(R)$ there exists scalars $c_0, c_1, \cdots, c_n$ such that\\
$g(x) = c_0f(x) + c_1f'(x) + c_2f'(x) + \cdots + c_nf^{\(n\)}(x)$
\begin{proof}
Let $O$ be the set of all odd functions in $F(F_1, F_2)$ and $E$ be the set of all even functions in $F(F_1, F_2)$.
\begin{enumerate}[label=\alph*.]
	\item{
			$0 \in O$ and $0 \in E$\\
			$\text{Zero function is defined as } g(x) = 0$\\
			\\$0\in O$ is odd: 
			\begin{Dequation}
			\begin{align*}
				g(-x) & = 0\\
				-g(x) & = 0\\
				g(-x) & = -g(x)
			\end{align*}
			\end{Dequation}

			\-\\$0\in E$ is even: 
			\begin{Dequation}
			\begin{align*}
				g(x) & = 0\\
				g(-x) & = 0\\
				g(x) & = g(-x)
			\end{align*}
			\end{Dequation}
		}
	
	\item{
		$X + Y \in O \text{ where } X,Y \in O$ and $t \in F_1$
		\begin{Dequation}
		\begin{align*}
			(X + Y)(-t) & = X(-t) + Y(-t) \\
						& = -X(t) + -Y(t)\tag{$X,Y \in O$}\\
			& = -(X + Y)(t)
		\end{align*}
		\end{Dequation}
		$X + Y \in E \text{ where } X,Y \in E$ and $t \in F_1$
		\begin{Dequation}
		\begin{align*}
			(X + Y)(t) & = X(t) + Y(t) \\
						& = X(-t) + Y(-t)\tag{$X,Y \in E$}\\
			& = (X + Y)(-t)
		\end{align*}
		\end{Dequation}
		}
	\item{
			$cX \in O \text{ where } c \in F \text{ and } X \in O \text{ and } t \in F_1$
			\begin{Dequation}
			\begin{align*}
				(cX)(-t) & = cX(-t) \\
						 & = -cX(t) \\
			\end{align*}
			\end{Dequation}
			
			$cY \in E \text{ where } c \in F \text{ and } Y \in E \text{ and } t \in F_1$
			\begin{Dequation}
			\begin{align*}
				(cY)(t) & = cY(t) \\
						 & = cY(-t) \\
			\end{align*}
			\end{Dequation}
		}
	\end{enumerate}	
	Therefore, $O$ and $E$ are subspaces of $F(F_1,F_1)$
\end{proof}

\section{C}
$W_1 = \{(a_1, a_2, \cdots, a_n) \in F^n : a_n = 0 \}$ \\
$W_2 = \{(a_1, a_2, \cdots, a_n) \in F^n : a_1 = a_2 = \cdots = a_{n-1} = 0 \}$ \\
Show $F^n$ = $W_1 \oplus W_2$
\begin{proof}
Definition of direct sum is $W_1 \cap W_2 = \{0\}$ and $W_1 + W_2 = F^n$
\begin{enumerate}[label=\alph*.]
	\item{
		$W_1 \cap W_2 = \{0\}$\\
		\-\\Let $v \in W_1,W_2$\\
		$v = (a_1, a_2, \cdots, a_n)$\\
		$v \in W_1 \Rightarrow a_n = 0$\\
		$v \in W_2 \Rightarrow a_1 = a_2 = \cdots = a_{n-1} = 0 $\\
		$\therefore v = (0, 0, \cdots, 0) \Rightarrow W_1 \cap W_2 = \{0\}$
		}
	\item{
		$W_1 + W_2 = F^n$\\
		\-\\ Let $v \in F^n$\\
		$v = (a_1, a_2, \cdots, a_n)$\\
		Let $w_1 \in W_1$ and $w_2 \in W_2$\\
		$w_1 = (a_1, a_2, \cdots, a_{n-1}, 0)$\\
		$w_2 = (0, 0, \cdots, a_n)$\\
		$w_1 + w_2 = (a_1, a_2, \cdots, a_n) = v$\\
		Thus, any vector in $F^n$ can be expressed as a sum of vectors in $W_1$ and $W_2$\\
		$\therefore W_1 + W_2 = F^n$
		}
\end{enumerate}
$\therefore F^n = W_1 \oplus W_2$
\end{proof}

\section{D}
In $M_{mxn}(F)$\\
$W_1 = \{A\in M_{mxn}(F): A_{i,j} = 0 \text{ whenever }i>j\}$\\
$W_2 = \{B\in M_{mxn}(F): B_{i,j} = 0 \text{ whenever }i \leq j\}$\\
Show that $M_{mxn}(F) = W_1 \oplus W_2$
\begin{proof}
\-\
\begin{enumerate}[label=\alph*.]
	\item{
			$W_1 \cap W_2 = \{0\}$\\
			\-\\ Let $m \in W_1, W_2$\\
			$m \in W_1 \Rightarrow m_{i,j} = 0 \text{ whenever }i>j$\\
			$m \in W_2 \Rightarrow m_{i,j} = 0 \text{ whenever }i \leq j$\\
			Thus, $(\forall i,j)(m_{i,j} = 0)$ which is \{0\}\\
			$\therefore W_1 \cap W_2 = \{0\}$\\
		}	
	\item{
			$W_1 + W_2 = M_{mxn}(F)$\\
			\-\\ Let $q \in M_{mxn}(F)$\\
			%$q = (a_1, a_2, \cdots, a_n)$\\
			Let $w_1 \in W_1$ and $w_2 \in W_2$\\
			$w_1 = \{(w_1)_{i,j} = 0 \text{ whenever }i>j \}$\\ 
			$w_2 = \{(w_2)_{i,j} = 0 \text{ whenever }i\leq j \}$\\ 
			$w_1 + w_2 = \{(w_1)_{i,j} \text{ wherever } i \leq j \text{ and } (w_2)_{i,j} \text{ wherever } i>j \} = q$\\
			Thus, any matrix in $M_{mxn}(F)$ can be expressed as a sum of matrices in $W_1$ and $W_2$\\
			$\therefore W_1 + W_2 = M_{mxn}(F)$
		}	
\end{enumerate}
$\therefore M_{mxn}(F) = W_1 \oplus W_2$
\end{proof}

\section{E}
Let $W$ be a subspace of a vector space $V$ over a field $F$.\\
For any $v \in V$ the set $\{v\} + W = \{v + w : w \in W \}$ is the coset $W$ containing $v$.
\begin{enumerate}[label=\alph*.]
	\item{
		Prove that $v + W$ is in the subspace of $V$ if and only if $v \in W$.
		\begin{proof}
			\-\\
			$v + W$ is in the subspace of $V \Rightarrow v \in W$.\\
			$0 \in v + W$ because $v + W$ is a subspace.\\
			$0 = v + w, w \in W$\\
			$v = -w$\\
			$v \in W$\\ 
			\-\\
			$v \in W \Rightarrow v + W$ is in the subspace of $V$.
			\begin{enumerate}[i.]
			\item{
			$0 \in v + W$\\
			$w \in W$ and let $v = -w$\\
			$v + w = 0$\\
			Thus, $0 \in v + W$
			}
			\item{
			$a + b \in v + W$ where $a,b \in v + W$\\
			Let $a = v + w_a, w_a \in W$ and $b = v + w_b, w_b \in W$ \\
			$a + b = v + w_a + v + w_b$\\
			Because $v \in W$, $w_a + v + w_b \in W$.\\
			Thus, $a + b \in v + W$
			}
		\item{
			$ca \in v + w, a \in v+W, c \in F$\\
			Let $a = v + w_a, w_a \in W$\\
			$ca = c(v + w_a)$\\
			$= cv + cw_a$\\
			$= v + cv + cw_a - v$\\
			$cv + c_wa - v \in W$ by closure under scalar multplication and vector addition.\\
			Thus, $ca \in v + w$
			}
		\end{enumerate}
		\end{proof}
	\item{
		 Prove that $v_1 + W = v_2 + W$ if and only if $v_1 - v_2 \in W$
		 \begin{proof}
			 \-\
			\begin{enumerate}[i.]
			\item{
				$v_1 + W = v_2 + W \Rightarrow v_1 - v_2 \in W$\\
				Let $w_1, w_2 \in W$\\
				$v_1 + w_1 = v_2 + w_2$\\
				$v_1 - v_2 = w_2 - w_1$\\
				Since, $w_2 - w_1 \in W$ (clourse under addition)\\
				Therefore, $v_1 - v_2 \in W$
				}
			\item{
				$v_1 - v_2 \in W \Rightarrow v_1 + W = v_2 + W $\\
				This means $v_1 - v_2 = w$ where $w \in W \ (*)$\\
				Now let $x \in v_1 + W$\\
				By definition, $\exists w_x \in W : x = v_1 + w_x$\\
				By $(*) \ v_1 = v_2 + w$\\
				So, $x = v_2 + w + w_x$\\
				Since, $w + w_x \in W$ (closure under addition)\\
				We have $x \in v_2 + W$\\
				So, $v_1 + W \subseteq v_2 + W$\\
				Similarly, we can show $v_2 + W \subseteq v_1 + W$\\
				Therefore, $v_1 + W = v_2 + W$

				}
			\end{enumerate}
		 \end{proof}
		}
	\item{
			Show that if $v_1 + W = v'_1 + W$ and $v_2 + W = v'_2 + W$, then \\
			$(v_1 + W) + (v_2 + W) = (v'_1 + W) + (v'_2 + W)$ and \\
			$a(v_1 + W) = a(v'_1 + W)$ for all $a \in F$
			\begin{proof}
				\-\
			\begin{enumerate}[i.]
				\item{
					$(v_1 + W) + (v_2 + W) = (v'_1 + W) + (v'_2 + W)$\\
					Let $q \in (v_1 + W) + (v_2 + W)$\\
					$q \in (v_1 + v_2) + W$ by definition of vector addition \\
					So, $q = v_1 + v_2 + w_q$ where $w_q \in W$\\
					$ = v_1 + v_2 + w_q + v'_1 - v'_1 + v'_2 - v'_2$\\
					$ = v'_1 + v'_2 + w_q + v_1 - v'_1 + v_2 - v'_2$\\
					From b. i, $v_1 - v'_1$ and $v_2 - v'_2 \in W$\\
					Which means, $(v_1 - v'_1) + (v_2 - v'_2) \in W$\\
					Thus, $w_q + v_1 - v'_1 + v_2 - v'_2 \in W$\\
					So, $q \in (v'_1 + v'_2) + W$\\
					So, $(v_1 + W) + (v_2 + W) \subseteq (v'_1 + W) + (v'_2 + W)$\\
					Similarly, we can show $(v'_1 + W) + (v'_2 + W) \subseteq (v_1 + W) + (v_2 + W)$\\
					Therefore, $(v_1 + W) + (v_2 + W) = (v'_1 + W) + (v'_2 + W)$\\
					
				
				}
				\item{	
				$a(v_1 + W) = a(v'_1 + W)$\\
				Let $q \in a(v_1 + W)$\\
				$q \in av_1 + W$ by definition of scalar multplication.\\
				So, $q = av_1 + w_q$ where $w_q \in W$\\
				$ = av_1 + w_q + av'_1 - av'_1$\\
				$ = av'_1 + w_q + av_1 - av'_1$\\
				$ = av'1 + a(v_1 - v'_1) + w_q$\\
				From b. i, $a(v_1 - v'_1) \in W$\\ 
				$a(v_1 - v'_1) + w_q \in W$ because closure under vector addition.\\
				So, $q \in av'_1 + W$\\
				So, $a(v_1 + W) \subseteq a(v'_1 + W)$\\
				Similarly, we can show $a(v'_1 + W) \subseteq a(v_1 + W)$\\
				Therefore, $a(v_1 + W)  = (v'_1 + W)$
				}
			\end{enumerate}
			\end{proof}
		}
	}	
\item{
		Prove that the set $S$ is a vector space with the operations defined in (c).	
	\begin{enumerate}[i.]
	\item{
		$0 \in S$\\
		The zero vector in $S$ is $ 0 = v_0 + W$\\
		Let $s \in S$\\
	    So $s = v_s + W$\\
		If the zero vector exists we should be able to show, $s + 0 = s$\\
		$s + 0 = s \Leftrightarrow (v_s + W) + (v_0 + W) = v_s + W$\\
		$(v_s + v_0) + W = v_s + W$ by definition of addition\\
		Thus $v_0 = 0$ and the zero vector is $0 + W$ which is just $W$\\
		Therefore, the zero vector is $W$.\\
		}
	\item{
		$X + Y \in S$ where $X,Y \in S$\\
	    This means $X = v_x + W$ \quad $Y = v_y + W$\\	
		$X + Y = (v_x + W) + (v_y + W)$
		$= (v_x + v_y) + W$ by defintion of addition.\\
		$(v_x + v_y) \in V$ by closure under vector addition.\\
		Therefore $X + Y \in S$\\
		}
	\item{
		$aX \in S \quad a \in F$\\
		$aX = a(v_x + W)$\\
		$= av_x + W$\\
		$av_x \in V$ by closure under vector addition.\\
		Therefore, $aX \in S$
		}
	\end{enumerate}
	}
\end{enumerate}

\section{F}
Show that if 
\[
M_1 = 
\begin{pmatrix}
1 & 0 \\
0 & 0 
\end{pmatrix},
M_2 = 
\begin{pmatrix}
0 & 0 \\
0 & 1 
\end{pmatrix},
\
M_3 = 
\begin{pmatrix}
0 & 1 \\
1 & 0 
\end{pmatrix}
\]
then the span of $\{M_1, M_2, M_3\}$ is the set of all symmetric $2x2$ matrices.

\begin{proof}
	\-\\
	$Sym(M_{2x2}(F)) = \{m \in M_{2x2}(F): m = \begin{pmatrix} a & b \\ b & c \end{pmatrix}  \Leftrightarrow m = m^t\}$
	\begin{Dequation}
	\begin{align*}
		m \in span(\{M_1, M_2, M_3\}) \text{ if } m & = c_1 
	\begin{pmatrix}
	1 & 0 \\
	0 & 0 
	\end{pmatrix}+
	c_2
	\begin{pmatrix}
	0 & 0 \\
	0 & 1 
	\end{pmatrix}+
	c_3
	\begin{pmatrix}
	0 & 1 \\
	1 & 0 
	\end{pmatrix}, \text{where } c_1, c_2, c_3 \in F\\
	& =\begin{pmatrix}
	c_1 & c_3 \\
	c_3 & c_2 
	\end{pmatrix}\\
		m^t & = 
	\begin{pmatrix}
	c_1 & c_3 \\
	c_3 & c_2 
	\end{pmatrix}
	\end{align*}
	\end{Dequation}
	$\therefore Sym(M_{2x2}(F)) = span(\{M_1, M_2, M_3\})$
\end{proof}

\section{G}
Show that if $S_1$ and $S_2$ are subsets of the vector space $V$ such that $S_1 \subseteq S_2$ then span($S_1$) $\subseteq$ span($S_2$). 
In particular, if $S_1 \subseteq S_2$ and span($S_1$) = $V$, deduce that span($S_2$) = $V$
\begin{proof}
	\-\\
	Let $z_1 \in \text{span}(S_1)$ \\ %and $z_2 \in \text{span}(S_2)$ \\
	So $z_1 = \sum_{i=1}^{n}a_ix_i$ where $a \in F$ and $x \in S_1$\\
	%$z_2 = \sum_{i=1}^{n}b_iy_i$ where $b \in F$ and $y \in S_2$\\
	If $S_1 \subseteq S_2$, then $x \in S_2$\\
	So $z_1 \in \text{span}(S_2)$ because we can write $z_1$ as a linear combination of $S_2$\\
	Therefore, if  $S_1 \subseteq S_2$ then $\text{span}(S_1) \subseteq \text{span}(S_2) \quad (*)$\\
	%As defined in the problem $S_2 \subseteq V$\\
	Defined in the problem, span($S_1$) = $V$\\
	By $(*)$, span($S_1$) $= V \subseteq$ span($S_2$)\\
	Using theorem 1.5, span($S_2$) $\subseteq V$\\
	Therefore, span($S_2$) $\subseteq V \subseteq$ span($S_2$) $\Leftrightarrow V = $ span($S_2$)
\end{proof}

\section{H} 
Show that $P_n(F)$ is generated by $\{1, x, \cdots, x^n\}$
\begin{proof}
	\-\\
	Definition of generates is span($\{1, x, \cdots, x^n\}$) = $P_n(F)$\\
	%$x \in P_n(F) \Leftrightarrow x \in \text{span}(\{1, x, \cdots, x^n\}) $\\
	\-\\
	First let's show that $\text{span}(\{1, x, \cdots, x^n\}) \subseteq P_n(F)$\\
	By theorem 1.5, this is true because $\{1, x, \cdots, x^n\} \subset P_n(F)$\\
	\-\\
	Now let's show that $P_n(F) \subseteq \text{span}(\{1, x, \cdots, x^n\})$\\
	Let $w \in P_n(F)$\\
	$w = a_nx^n + a_{n-1}x^{n-1} + \cdots + a_0x^0$ where $a\in F$\\
	Let $ v\in \text{span}(\{1, x, \cdots, x^n\})$ where $b \in F$\\
	$v = b_01 + b_2x + \cdots + b_n x^n$ \\
	Any w can be expressed as a v, if we fix $a_0 = b_0, \cdots, a_n = b_n$.\\	
	Thus, $P_n(F) \subseteq \text{span}(\{1, x, \cdots, x^n\})$\\
	\-\\
	Therefore, $P_n(F)$ is generated by $\{1, x, \cdots, x^n\}$
\end{proof}
\section{I} 
In $M_{mxn}(F)$, let $E^{ij}$ denote the matrix whose only nonzero entry is 1 in the $i$th row and $j$th column. Prove that $\{E^{ij}: 1 \leq i \leq m,
1 \leq j \leq n\}$ is linearly independent.
\begin{proof}
	\-\\
	If $E^{ij}$ is linearly independent then $a_{1,1}E^{1,1} + \cdots + a_{m,n}E^{m,n} \neq 0$\\
	This sum can only equal the 0 matrix if all a are 0.\\
	Therefore, $E^{ij}$ is linearly independent.
	%If $E^{ij}$ is linearly independent then $\sum_{/i=1}^{m} \sum_{j=1}^{n} a_{ij}E_{ij} \neq 0$ where not all a are 0.\\
	%The only time where the above sum equals the 0 matrix is if all a are 0. 
	%Given the definition of $E^{ij}$, we can rewrite the above sum as $\sum_{i=1}^{m} a_{i0} + \sum_{j=1}^{n}a_{0j}$ 
\end{proof}
\section{J}
Let $u$ and $v$ be distinct vectors in a vector space $V$. Show that $\{u,v\}$ is linearly dependent if and only if $u$ or $v$ is a
multiple of the other.

\begin{proof}
\-\\
	Let's first show that if $u$ or $v$ is a multiple of the other then $\{u,v\}$ is linearly dependent.\\
	Being a mutiple means $u = nv$ or $v = nu$ where $n \in F$ \\
	If $\{u,v\}$ is linearly dependent then $a_1u + a_2v = 0$ where $a \in F$\\
	Using definition of mutiple $a_1u + a_2nu = 0$\\
	Factoring, $u(a_1 + a_2n) = 0$\\
	This means $(a_1 + a_2n) = 0$\\	
	So, $n = \frac{-a_1}{a_2}$ which is a solution for linearly dependency.\\
	Without loss of generality, we can prove the case where $ v = nu$\\
	Therefore, $\{u,v\}$ is linearly dependent.\\
	\-\\
	Now let's show that if $\{u,v\}$ is linearly dependent then $u$ or $v$ is a multiple of the other.\\
	If $\{u,v\}$ is linearly dependent then $a_1u + a_2v = 0$ where $a \in F$\\
	We can rewrite the equation above as $a_1u = -a_2v$\\
	$u = \frac{-a_2}{a_1}v$\\
	Thus, $u$ is a multiple of $v$.\\
	Without loss of generality, we can prove $v$ is a multiple of $u$.\\
	Therefore, $u$ or $v$ is a mutiple of the other.
\end{proof}
\end{document}
