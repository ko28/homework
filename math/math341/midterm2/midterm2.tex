\documentclass[11pt]{scrartcl}
\usepackage[sexy]{../../evan}
\usepackage{cmbright}
\usepackage{cancel}
\usepackage[T1]{fontenc}
%\usepackage{enumerate}
\usepackage[shortlabels]{enumitem}
\usepackage[utf8]{inputenc}
\usepackage[margin=1in]{geometry}
%\usepackage[pdfborder={0 0 0},colorlinks=true,citecolor=red{}]{hyperref}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{setspace}
\usepackage{systeme}

\makeatletter
\newenvironment{Dequation}
{%
  \def\tagform@##1{%
    \maketag@@@{\makebox[0pt][r]{(\ignorespaces##1\unskip\@@italiccorr)}}}%
  \ignorespaces
  }
  {%
  \def\tagform@##1{\maketag@@@{(\ignorespaces##1\unskip\@@italiccorr)}}%
  \ignorespacesafterend
  }
\makeatother

\title{Math 341: Midterm 2}
\author{Daniel Ko}
\date{Spring 2020}

\begin{document}
\maketitle

%problem 1
\section{}
Let
\begin{equation}
	\mathbf{A} = \left [ \begin{array}{cc}
			a & b \\
			c & d
		\end{array} \right ],
	\mbox{ and  } \mathbf{b} = \left ( \begin{array}{c}
			e \\
			f
		\end{array} \right )
\end{equation}
\begin{enumerate}[label=\alph*.]
	\item{
	      Suppose that $a\neq 0 $, compute the solution of $\mathbf{Ax = b}$
	      using row reduction and provide the conditions on $a,b,c,d$ such that your computations are valid.
	      Express the result as a simplified expression. (\textbf{Hint:} recall that you can not divide by zero)
	      \begin{proof}
		      We perform reduced row echelon form (rref) on the augmented matrix
		      \begin{align*}
			      (A|b)=
			      \left[\begin{array}{cc|c}
					      a & b & e \\
					      c & d & f
				      \end{array}\right] \\
			      R_2 \leftarrow R_2 - \frac{c}{a} R_1
			      \left[\begin{array}{cc|c}
					      a & b                & e                \\
					      0 & d - \frac{cb}{a} & f - \frac{ce}{a}
				      \end{array}\right] \\
			      \left[\begin{array}{cc|c}
					      a & b               & e               \\
					      0 & \frac{ad-cb}{a} & \frac{af-ce}{a}
				      \end{array}\right] \\
			      R_2 \leftarrow \frac{a}{ad-cb}R_2 \quad \text{Assuming that $ab-cd \neq 0$} \quad
			      \left[\begin{array}{cc|c}
					      a & b & e                   \\
					      0 & 1 & \frac{af-ce}{ad-cb}
				      \end{array}\right] \\
			      R_1 \leftarrow R_1 - bR_2
			      \left[\begin{array}{cc|c}
					      a & 0 & e -b \frac{af-ce}{ad-cb} \\
					      0 & 1 & \frac{af-ce}{ad-cb}
				      \end{array}\right] \\
			      R_1 \leftarrow \frac{R_1}{a}
			      \left[\begin{array}{cc|c}
					      1 & 0 & \frac{1}{a}(e -b \frac{af-ce}{ad-cb}) \\
					      0 & 1 & \frac{af-ce}{ad-cb}
				      \end{array}\right] \\
			      \left[\begin{array}{cc|c}
					      1 & 0 & \frac{de-bf}{ad-cb} \\
					      0 & 1 & \frac{af-ce}{ad-cb}
				      \end{array}\right]
		      \end{align*}

		      \[x =
			      \begin{bmatrix}
				      \frac{de-bf}{ad-cb} \\
				      \frac{af-ce}{ad-cb}
			      \end{bmatrix} =
			      \frac{1}{ad-cb}
			      \begin{bmatrix}
				      de-bf \\
				      af-ce
			      \end{bmatrix}
			      \text{ where } ad-cb \neq 0
		      \]
	      \end{proof}
	      }
	\item{
	      If $a = 0$, and $c\neq 0$, is your above computation still valid?
	      How would you modify it? (explain briefly)
	      (\textbf{Hint:} recall that you can swap the equations and the result is the same)
	      \begin{proof}
		      If $a = 0$, and $c\neq 0$, then the above computation will not be valid as we
		      divided by $a$ multiple times when we computed the rref. I would swap the first
		      and second rows so that it would look like
		      \[
			      \left[\begin{array}{cc|c}
					      c & d & f \\
					      0 & b & e
				      \end{array}\right]
		      \]
		      and compute the rref, assuming that $b\neq0$. We obtain the rref,
		      \[
			      \left[\begin{array}{cc|c}
					      1 & 0 & \frac{bf-de}{bc} \\
					      0 & 1 & \frac{e}{b}
				      \end{array}\right]
		      \]
		      and the solution
		      \[
			      x=
			      \begin{bmatrix}
				      \frac{bf-de}{bc} \\
				      \frac{e}{b}
			      \end{bmatrix} \quad \text{ where } b \neq 0
		      \]
	      \end{proof}
	      }
	\item{
	      If $a = 0$, $c=0$, but $b \neq 0$, $d \neq 0$,
	      what are the conditions on $e$ and $f$ such that the system $\mathbf{Ax=b}$ has a solution?
	      Is the solution unique?  (\textbf{Hint:} recall that $\mathbf{Ax = b}$ has a solution if and only if
	      $\mathbf{b}$ can be written as a linear combination of the columns of $\mathbf{A}$)
	      \begin{proof}
		      If $a = 0$, $c=0$, $b \neq 0$, $d \neq 0$, we get the augmented matrix
		      \[
			      \left[\begin{array}{cc|c}
					      0 & b & e \\
					      0 & d & f
				      \end{array}\right]
		      \]
		      Performing row reduction,
		      \[
			      \left[\begin{array}{cc|c}
					      0 & 1 & \frac{e}{b} \\
					      0 & 1 & \frac{f}{d}
				      \end{array}\right]
		      \]
		      Having an infinite amount of solutions is by definition another way of saying
		      that a system that is consistent and that the solutions are not unique.

		      It is clear that det$(\mathbf{A}) = 0$ by multiplying the diagonal entries because it is an
		      upper triangular matrix. This means that
		      the solution, if it exists, is not unique by
		      Theorem 3.10 and the corollary to Theorem 4.7. A system is consistent if and only if
		      $rank(\mathbf{A}) = rank(\mathbf{A}|\mathbf{b})$ by Theorem 3.11.
		      For this condition to hold,
		      \[
			      \mathbf{b} \in span(\mathbf{A}) \Leftrightarrow
			      \begin{pmatrix}
				      \frac{e}{b} \\
				      \frac{f}{d} \\
			      \end{pmatrix}
			      =
			      c_1
			      \begin{pmatrix}
				      0 \\
				      0 \\
			      \end{pmatrix} +
			      c_2
			      \begin{pmatrix}
				      1 \\
				      1 \\
			      \end{pmatrix}
			      \text{ where } c_1,c_2 \in F
		      \]
		      So the condition of the solution is,
		      \begin{align*}
			      c_2         & = \frac{e}{b}  \\
			      c_2         & =  \frac{f}{d} \\
			      \frac{e}{b} & = \frac{f}{d}
		      \end{align*}
		      %$$x_2 = \frac{e}{b} = \frac{f}{d}$$
		      Thus, there exists a infinite amount of solution.
	      \end{proof}
	      }
	\item{
	      Solve the system
	      \begin{equation}
		      \left [ \begin{array}{cc}
				      \sqrt{2}  & 3\sqrt{2} \\
				      2\sqrt{2} & \sqrt{2}
			      \end{array} \right ] \left ( \begin{array}{c}
				      x_1 \\
				      x_2
			      \end{array} \right ) = \left ( \begin{array}{c}
				      5\sqrt{2} \\
				      5\sqrt{2}
			      \end{array} \right ).
	      \end{equation}
	      (\textbf{Hint:} You may want to use the formula you just deduced)
	      }
	      \begin{proof}
		      \begin{align*}
			      x_1 & = \frac{de-bf}{ad-cb}                                                        \\
			          & = \frac{\sqrt2(5\sqrt2) - 3\sqrt2(5\sqrt2)}{\sqrt2\sqrt2 - 3\sqrt2(2\sqrt2)} \\
			          & = \frac{10 - 30}{2-12}                                                       \\
			          & = \frac{-20}{-10}                                                            \\
			          & = 2                                                                          \\
			          &                                                                              \\
			      x_2 & = \frac{af-ce}{ad-cb}                                                        \\
			          & = \frac{\sqrt2(5\sqrt2) - 2\sqrt2(5\sqrt2)}{\sqrt2\sqrt2 - 3\sqrt2(2\sqrt2)} \\
			          & = \frac{10-20}{-10}                                                          \\
			          & = 1
		      \end{align*}
	      \end{proof}
\end{enumerate}

%problem 2
\section{}
Let
\begin{equation}
	\mathbf{A} = \left [ \begin{array}{cccc}
			0  & - \alpha & 2  & 0             \\
			1  & 1        & 0  & 1             \\
			2  & 2        & 2  & 3             \\
			-2 & -2       & 4  & 2\alpha       \\
			0  & \alpha   & -1 & 2\alpha + 1/2
		\end{array} \right ], \qquad  \mbox{and }
	\mathbf{b} =  \left [ \begin{array}{c}
			2          \\
			1          \\
			4          \\
			2 + \alpha \\
			2 \beta + \alpha -2
		\end{array} \right ]
\end{equation}
What are the conditions on $\alpha$ and $\beta$ such that the system $\mathbf{A} \mathbf{x} = \mathbf{b}$:
\begin{enumerate}[label=\alph*.]
	\item{
	      Has no solution?
	      \begin{proof}
		      We begin by putting the augmented matrix $(\mathbf{A}|\mathbf{b})$ in its reduced form.
		      \begin{align*}
			      (\mathbf{A}|\mathbf{b})=
			      \left [ \begin{array}{cccc|c}
					      0  & - \alpha & 2  & 0             & 2                  \\
					      1  & 1        & 0  & 1             & 1                  \\
					      2  & 2        & 2  & 3             & 4                  \\
					      -2 & -2       & 4  & 2\alpha       & 2 + \alpha         \\
					      0  & \alpha   & -1 & 2\alpha + 1/2 & 2\beta + \alpha -2
				      \end{array} \right ] \\
			      R_5 \leftarrow R_5 + R_1
			      \left [ \begin{array}{cccc|c}
					      0  & - \alpha & 2 & 0             & 2               \\
					      1  & 1        & 0 & 1             & 1               \\
					      2  & 2        & 2 & 3             & 4               \\
					      -2 & -2       & 4 & 2\alpha       & 2 + \alpha      \\
					      0  & 0        & 1 & 2\alpha + 1/2 & 2\beta + \alpha
				      \end{array} \right ] \\
			      R_3 \leftarrow R_3 - 2R_2
			      \left [ \begin{array}{cccc|c}
					      0  & - \alpha & 2 & 0             & 2               \\
					      1  & 1        & 0 & 1             & 1               \\
					      0  & 0        & 2 & 1             & 2               \\
					      -2 & -2       & 4 & 2\alpha       & 2 + \alpha      \\
					      0  & 0        & 1 & 2\alpha + 1/2 & 2\beta + \alpha
				      \end{array} \right ] \\
			      R_4 \leftarrow R_4 + 2 R_2
			      \left [ \begin{array}{cccc|c}
					      0 & - \alpha & 2 & 0             & 2               \\
					      1 & 1        & 0 & 1             & 1               \\
					      0 & 0        & 2 & 1             & 2               \\
					      0 & 0        & 4 & 2\alpha  +2   & 4 + \alpha      \\
					      0 & 0        & 1 & 2\alpha + 1/2 & 2\beta + \alpha
				      \end{array} \right ] \\
			      R_4 \leftarrow R_4 - 2R_3,R_5 \leftarrow R_5 - \frac12R_3
			      \left [ \begin{array}{cccc|c}
					      0 & - \alpha & 2 & 0       & 2                   \\
					      1 & 1        & 0 & 1       & 1                   \\
					      0 & 0        & 2 & 1       & 2                   \\
					      0 & 0        & 0 & 2\alpha & \alpha              \\
					      0 & 0        & 0 & 2\alpha & 2\beta + \alpha + 1
				      \end{array} \right ] \\
			      R_5 \leftarrow R_5 - R_4
			      \left [ \begin{array}{cccc|c}
					      0 & - \alpha & 2 & 0       & 2          \\
					      1 & 1        & 0 & 1       & 1          \\
					      0 & 0        & 2 & 1       & 2          \\
					      0 & 0        & 0 & 2\alpha & \alpha     \\
					      0 & 0        & 0 & 0       & 2\beta - 1
				      \end{array} \right ] \\
			      R_1 \leftrightarrow R_2 \quad (\mathbf{A'}|\mathbf{b'} ) = 
			      \left [ \begin{array}{cccc|c}
					      1 & 1        & 0 & 1       & 1          \\
					      0 & - \alpha & 2 & 0       & 2          \\
					      0 & 0        & 2 & 1       & 2          \\
					      0 & 0        & 0 & 2\alpha & \alpha     \\
					      0 & 0        & 0 & 0       & 2\beta - 1
				      \end{array} \right ]
		      \end{align*}
		      By Theorem 3.11 and 3.13, a system is consistent if and only if $rank(\mathbf{A'}) = rank(\mathbf{A'}|\mathbf{b'})$.
			  Thus this system will have no solution if $2\beta - 1 \neq 0$ because then $\mathbf{b'} \notin span(\mathbf{A'})$.
			  
			 This is when $\beta \neq \frac12$.
		      We observe that there will be no conditions on $\alpha$.
		      %show that b \in R(L_A) ?? 
	      \end{proof}
	      }
	\item{
	      Has an unique solution? Find the solution.
	      (\textbf{Hint:} you will need to row reduce the augmented system to echelon form,
	      and then use the theorems seen in class to impose the conditions on $\alpha$ and $\beta$).
	      \begin{proof}
		      Combining Theorem 3.10 and the corollary to Theorem 4.7, we get that a system has a
		      unique solution if and only if det$(\mathbf{A}) \neq 0$.
		      The determinant of an upper triangular matrix is the product of its diagonal
		      entries by property 4 of determinants in section 4.4.
		      %IF the above fact is not allowed, I will write out the full recursive definition 
		      Using this fact we can compute the condition of $\alpha$ as such that
		      \begin{align*}
			      1*-\alpha*2*2\alpha & \neq 0 \\
			      -4\alpha^2          & \neq 0 \\
			      \alpha              & \neq 0
		      \end{align*}
		      and from (a), $\beta = \frac12$. Combining these two conditions we get the following system,
		      \[
			      \left [ \begin{array}{cccc|c}
					      1 & 1        & 0 & 1       & 1      \\
					      0 & - \alpha & 2 & 0       & 2      \\
					      0 & 0        & 2 & 1       & 2      \\
					      0 & 0        & 0 & 2\alpha & \alpha \\
					      0 & 0        & 0 & 0       & 0
				      \end{array} \right ]
		      \]
			  By performing back substitution we compute the unique solution
			  \begin{align*}
				2\alpha x_4 = \alpha & \Leftrightarrow x_4 = \frac12 \\
				2x_3 + x_4 = 2 & \Leftrightarrow x_3 = \frac34   \\
				-\alpha x_2 + 2x_3 = 2 & \Leftrightarrow x_2  = -\frac{1}{2\alpha}\\
				x_1 + x_2 + x_4 = 1  & \Leftrightarrow x_ 1 =\frac12 + \frac{1}{2\alpha}
			\end{align*}

		      \[
			      x = \begin{bmatrix}
				      \frac12 + \frac{1}{2\alpha} \\
				      -\frac{1}{2\alpha}          \\
				      \frac34                     \\
				      \frac12
			      \end{bmatrix}
		      \]
		      as desired.
	      \end{proof}
	      }

	\item{
	      Has infinite amount of solutions? Find the solution set in parametric form.
	      (\textbf{Hint:} You may have one equations for $\alpha$ and one for $\beta$ that have to be satisfied simultaneously).
	      \begin{proof}
		      Having an infinite amount of solutions is by definition another way of saying
		      that a system that is consistent and that the solutions are not unique.
		      A system is consistent if and only if $rank(\mathbf{A}) = rank(\mathbf{A}|\mathbf{b})$
		      by Theorem 3.11. If det$(\mathbf{A}) = 0$, the solution, if it exists, is not unique by
		      Theorem 3.10 and the corollary to Theorem 4.7.

		      Using this fact we can compute the condition of $\alpha$ as such that
		      \begin{align*}
			      1*-\alpha*2*2\alpha & = 0 \\
			      -4\alpha^2          & = 0 \\
			      \alpha              & = 0
		      \end{align*}
		      Given that $\alpha = 0$, and that $\beta = \frac12$ from part (a)
		      we get the following system,

		      \[
				(\mathbf{A'}|\mathbf{b'})=
			      \left [ \begin{array}{cccc|c}
					      1 & 1 & 0 & 1 & 1 \\
					      0 & 0 & 2 & 0 & 2 \\
					      0 & 0 & 2 & 1 & 2 \\
					      0 & 0 & 0 & 0 & 0 \\
					      0 & 0 & 0 & 0 & 0
				      \end{array} \right ]
		      \]
		      It is clear that  $rank(\mathbf{A'}) = rank(\mathbf{A'}|\mathbf{b'})$ because
		      $\mathbf{b'}$ is a linear combination of the second and third column from
			  $\mathbf{A'}$. By Theorem 3.13, we know that the solution set for $\mathbf{A'x=b'}$
			  is equivalent to the solution set for $\mathbf{Ax=b}$. Hence, both systems are consistent. \\
		      We can compute a solution space to $\mathbf{Ax=b}$ as outlined in Theorem 3.9. We start by first computing the
		      solution set to $\mathbf{Ax}=0$ denoted by $K_H$. It is clear that $rank(\mathbf{A}) = 3$ because the first two
		      columns are the same and the rest of the columns are linearly independent from each other.
		      By Theorem 3.8, $dim(K_H) = 4 - 3 = 1$. Thus any nonzero solution constitutes a basis for K. For example, since
		      $$
			      \begin{pmatrix}
				      1  \\
				      -1 \\
				      0  \\
				      0
			      \end{pmatrix}
		      $$
		      is a solution to the $\mathbf{Ax}=0$, it is a basis for $K_H$ by Corollary 2 of Theorem 1.10.
		      So a solution set to $K_H$ would be
		      \[
			      K_H=
			      \left\{
			      t\begin{pmatrix}
				      1  \\
				      -1 \\
				      0  \\
				      0
			      \end{pmatrix}: t \in \mathbb{R}
			      \right\}
		      \]
		      A solution to $\mathbf{Ax=b}$ is
		      $$
			      \begin{pmatrix}
				      1 \\
				      0 \\
				      1 \\
				      0
			      \end{pmatrix}
		      $$
		      Therefore, by Theorem 3.9 we compute solution space when this system has infinite amount of solutions, which is when $\alpha = 0$ and $\beta = \frac12$ as
		      \[
			      K=
			      \left\{
			      \begin{pmatrix}
				      1 \\
				      0 \\
				      1 \\
				      0
			      \end{pmatrix}+
			      t\begin{pmatrix}
				      1  \\
				      -1 \\
				      0  \\
				      0
			      \end{pmatrix}: t \in \mathbb{R}
			      \right\}
		      \]
	      \end{proof}
	      }
\end{enumerate}

%problem 3
\section{}
Let $A \in M_{n\times n}(F)$, for a field $F$.
We want to prove that $rank(A^2) - rank(A^3) \leq rank(A) - rank(A^2)$.
The solution to this exercise requires the notion of quotient spaces.
Even though you should already be familiar with quotient spaces we will prove a few properties that will be useful.\\ \-\\
Let \(\mathrm{W}\) be a subspace of a vector space \(\mathrm{V}\) over a field \(F .\) For any \(v \in \mathrm{V}\) the set \(\{v\}+\mathrm{W}=\{v+w: w \in \mathrm{W}\}\) is called the coset of W containing \(v .\) It is customary to denote this coset by \(v+W\) rather than \(\{v\}+W\).
Following this notation we write $\mathrm{V}/\mathrm{W} = \{ v + \mathrm{W}: v \in \mathrm{V} \}$, which is usually called the quotient space $\mathrm{V}$ module $\mathrm{W}$. Addition and scalar multiplication by scalars can be defined in the collection \(\mathrm{V}/\mathrm{W}\) as follows:
$$
	\left(v_{1}+\mathrm{W}\right)+\left(v_{2}+\mathrm{W}\right)=\left(v_{1}+v_{2}\right)+\mathrm{W}
$$
for all \(v_{1}, v_{2} \in \mathrm{V}\) and
$$
	a(v+W)=a v+W
$$
for all \(v \in \mathrm{V}\) and \(a \in F\)
\begin{enumerate}[label=\alph*.]
	%CHECK THIS , just copied and pasted from hw2 lol
	\item{
	      Prove that \(v_{1}+\mathrm{W}=v_{2}+\mathrm{W}\) if and only if \(v_{1}-v_{2} \in \mathrm{W}\).
	      (\textbf{Hint}: recall that $v_{1}+\mathrm{W}$ is a set, thus you need to prove equality between sets)
	      \begin{proof}\-\
		      \begin{enumerate}[i.]
			      \item{
			            $v_1 + W = v_2 + W \Rightarrow v_1 - v_2 \in W$\\
			            If $v_1 + W = v_2 + W$, then $\exists w_1, w_2 \in W$ such that
			            $v_1 + w_1 = v_2 + w_2$\\
			            $v_1 - v_2 = w_2 - w_1$\\
			            Since, $w_2 - w_1 \in W$ (clourse under addition)\\
			            Therefore, $v_1 - v_2 \in W$
			            }
			      \item{
			            $v_1 - v_2 \in W \Rightarrow v_1 + W = v_2 + W $\\
			            This means $v_1 - v_2 = w$ where $w \in W \ (*)$\\
			            Now let $x \in v_1 + W$\\
			            By definition, $\exists w_x \in W \text{ such that } x = v_1 + w_x$\\
			            By $(*) \ v_1 = v_2 + w$\\
			            So, $x = v_2 + w + w_x$\\
			            Since, $w + w_x \in W$ (closure under addition)\\
			            We have $x \in v_2 + W$\\
			            So, $v_1 + W \subseteq v_2 + W$\\
			            Without loss of generality, we can show $v_2 + W \subseteq v_1 + W$\\
			            Therefore, $v_1 + W = v_2 + W$
			            }
		      \end{enumerate}
		      Therefore, \(v_{1}+\mathrm{W}=v_{2}+\mathrm{W}\) if and only if \(v_{1}-v_{2} \in \mathrm{W}\)
	      \end{proof}
	      }

	\item{
	      Show that \(\mathrm{V}/\mathrm{W}\) with the operations defined above is a linear vector space.
	      \begin{enumerate}[label=VS \arabic*:]
		      \item{
		            For all $x, y$ in $\mathrm{V}/\mathrm{W}, x+y=y+x$ (commutativity of addition)
		            \begin{proof}
			            Let $x = v_x + W, y = v_y + W$ where $v_x,v_y \in V$.
			            \begin{align*}
				            x + y & = (v_x + W) + (v_y + W) \\
				                  & = (v_x + v_y) + W       \\
				                  & = (v_y + v_x) + W       \\
				                  & = (v_y + W) + (v_x + W) \\
				                  & = y + x
			            \end{align*}
		            \end{proof}
		            }
		      \item{
		            For all $x, y, z$ in $\mathrm{V}/\mathrm{W},(x+y)+z=x+(y+z)$ (associativity of addition)
		            \begin{proof}
			            Let $x = v_x + W, y = v_y + W, z = v_z + W,$ where $v_x,v_y,v_z \in V$.
			            \begin{align*}
				            (x + y) + z & = ((v_x + W) + (v_y + W)) + (v_z + W) \\
				                        & = ((v_x + v_y) + W) + (v_z + W)       \\
				                        & = (v_y + v_x + v_z) + W               \\
				                        & = (v_x + W) + ((v_y + v_z) + W)       \\
				                        & = (v_x + W) + ((v_y + W) + (v_z + W)) \\
				                        & = x + (y + z)
			            \end{align*}
		            \end{proof}
		            }
		      \item{
		            There exists an element in $\mathrm{V}/\mathrm{W}$ denoted by $\mathbf{0}$ such that $x+\mathbf{0}=x$ for each $x$ in $\mathrm{V}/\mathrm{W}$
		            \begin{proof}
			            Let $x = v_x + W$ where $v_x \in V$. Let $\mathbf{0}$ in $\mathrm{V}/\mathrm{W}$ be defined
			            as $0 + W$, where $0 \in V$.
			            \begin{align*}
				            x + \mathbf{0} & = x + (0 + W)         \\
				                           & = (v_x + W) + (0 + W) \\
				                           & = (v_x + 0) + W       \\
				                           & = v_x + W             \\
				                           & = x
			            \end{align*}
		            \end{proof}
		            }
		      \item{
		            For each element $x$ in $\mathrm{V}/\mathrm{W}$ there exists an element $y$ in $\mathrm{V}/\mathrm{W}$ such that $x+y=\mathbf{0}$
		            \begin{proof}
			            Let $x = v_x + W$ where $v_x \in V$. Fix y such that $y = -v_x + W$.
			            \begin{align*}
				            x + y & = (v_x + W) + (-v_x + W) \\
				                  & = (v_x - v_x) + W        \\
				                  & = 0 + W                  \\
				                  & = \mathbf{0}
			            \end{align*}
		            \end{proof}
		            }
		      \item{
		            For each element $x$ in $\mathrm{V}/\mathrm{W}, 1 x=x$
		            \begin{proof}
			            Let $x = v_x + W$ where $v_x \in V$.
			            \begin{align*}
				            1x & = 1(v_x + W) \\
				               & =(1v_x + W)  \\
				               & = (v_x + W)  \\
				               & = x
			            \end{align*}
		            \end{proof}
		            }
		      \item{
		            For each pair of elements $a, b$ in $\mathbb{F}$ and each element $x$ in $\mathrm{V}/\mathrm{W}$, $(a b) x=a(b x)$
		            \begin{proof}
			            Let $x = v_x + W$ where $v_x \in V$.
			            \begin{align*}
				            (a b) x & = abv_x + W  \\
				                    & =a(bv_x + W) \\
				                    & =a(bx)
			            \end{align*}
		            \end{proof}
		            }
		      \item{
		            For each element a in $\mathbb{F}$ and each pair of elements $x, y$ in $\mathrm{V}/\mathrm{W}$, $a(x+y)=a x+a y$
		            \begin{proof}
			            Let $x = v_x + W, y = v_y + W$ where $v_x,v_y \in V$.
			            \begin{align*}
				            a(x + y) & = a((v_x + v_y) + W)       \\
				                     & =((av_x + av_y) + W )      \\
				                     & =(av_x + W ) +  (av_y + W) \\
				                     & =a(v_x + W ) + a(v_y + W)  \\
				                     & =ax +ay
			            \end{align*}
		            \end{proof}
		            }
		      \item{
		            For each pair of elements $a, b$ in $\mathbb{F}$ and each element $x$ in $\mathrm{V}/\mathrm{W}$, $(a+b) x=a x+b x$
		            \begin{proof}
			            Let $x = v_x + W$ where $v_x \in V$.
			            \begin{align*}
				            (a + b)x & = (a + b)(v_x + W)         \\
				                     & = ((a + b)v_x) + W         \\
				                     & = ((av_x + bv_x) + W       \\
				                     & = (av_x + W) +  (bv_x + W) \\
				                     & = a(v_x + W) + b(v_x + W)  \\
				                     & = ax + bx
			            \end{align*}
		            \end{proof}
		            }
	      \end{enumerate}
	      Therefore, $\mathrm{V}/\mathrm{W}$ is a vector space because it holds all the properties above.
	      }

	\item{
	      Prove that if $dim(\mathrm{V}) < \infty$ then $dim(\mathrm{V}/\mathrm{W}) = dim(\mathrm{V}) - dim(\mathrm{W})$.
	      (Hint: Define a linear map $T:\mathrm{V} \rightarrow \mathrm{V}/\mathrm{W}$ such that the range of $T$ is $\mathrm{V}/\mathrm{W}$, and then use the rank-nullity theorem)
	      \begin{proof}We define the linear map $T:\mathrm{V} \rightarrow \mathrm{V}/\mathrm{W}$ by \[T(v) = v + W\]
		      We first prove that $T$ is in fact linear, where $v_1,v_2 \in V$ and $c \in F$.
		      \begin{align*}
			      T(cv_1 + v_2) & = (cv_1 + v_2) + W         \\
			                    & =  (cv_1 + W)+ ((v_2) + W) \\
			                    & =  c(v_1 + W)+ ((v_2) + W) \\
			                    & =  cT(v_1)+ T(v_2)
		      \end{align*}
		      We claim that $N(T) = W$ and $R(T) = \mathrm{V}/\mathrm{W}$
		      \begin{enumerate}[label=\arabic*.]
			      \item{
			            $R(T) = \mathrm{V}/\mathrm{W}$
			            \begin{enumerate}[label=\roman*.]
				            \item{
				                  $R(T) \subseteq \mathrm{V}/\mathrm{W}$\\
				                  By Theorem 2.1\\
				                  }
				            \item{
				                  $\mathrm{V}/\mathrm{W} \subseteq R(T)$\\
				                  Let $y = v_y + W$ where $y \in \mathrm{V}/\mathrm{W}$ and $v_y \in V$.\\
				                  For prove that $y \in N(T)$ we need to show that  $\exists x$ such that $ T(x) = y$.\\
				                  Notice that $x = v_y$. Therfore, $y \in R(T)$ so $\mathrm{V}/\mathrm{W} \subseteq R(T)$.

				                  }
			            \end{enumerate}
			            }
			      \item{
			            $N(T) = W$
			            \begin{enumerate}[label=\roman*.]
				            \item{
								  $N(T) \subseteq W$
								  \begin{lemma}
									$w_1 + W = w_2 + W$ where $w_1, w_2 \in W$.
									\begin{proof}\-\\
										Let $x_1 \in w_1 + W$ and $x_2 \in w_2 + W$\\
										By definition, $w_1 + W = \{w_1 + w : w \in W\}$.\\
										We know that $w_1 +w \in W$ because $W$ is a subspace and has closure under addition.
										Hence, $x_1 \in W$ and similarly $x_2 \in W$. Therefore, $w_1 + W \subseteq W$ and  $w_2 + W \subseteq W$.\\\-\\
										Now consider $x_1 \in W$ and $x_2 \in W$.\\
										$x_1 \in w_1 + W$ because $w_1 + w \in W$ by closure under addition\\
										Similarly, $x_2 \in w_2 + W$.\\
										Hence, $W \subseteq w_1 + W$ and $W \subseteq w_2 + W$.\\

										Therefore, $w_1 + W = W$ and $W = w_2 + W$ so, $w_1 + W = w_2 + W $. 

									\end{proof}
								  \end{lemma}
				                  Let $x \in N(T)$.\\ %By Theorem 2.1, we know that $N(T) \in V$, thus $x \in V$.\\
				                  By definition of $N(T)$ and using the lemma above,
				                  \begin{align*}
					                  T(x) & = \mathbf{0} \\
					                       & = 0 + W      \\
					                       & = w + W
				                  \end{align*}
				                  where $0, w \in W$ and $\mathbf{0} \in \mathrm{V}/\mathrm{W}$.\\
				                  This must mean that $x = w$ and since $w \in W$, $x \in W$. Therefore, $N(T) \subseteq W$\\
				                  }
				            \item{
				                  $W \subseteq N(T)$\\
				                  Let $w \in W$.
				                  \begin{align*}
					                  T(w) & = w + W      \\
					                       & = W          \\
					                       & = 0 + W      \\
					                       & = \mathbf{0}
				                  \end{align*}
				                  }
				                  So $w \in N(T)$. Therefore, $W \subseteq N(T)$.
			            \end{enumerate}
			            }
		      \end{enumerate}
		      Notice that $\mathrm{V}/\mathrm{W} \subseteq \mathrm{V}$
		      so $\mathrm{V}/\mathrm{W}$ is finite dimensional.
		      Since $T$ is a linear map and that $\mathrm{V}$ and $\mathrm{V}/\mathrm{W}$ are indeed finite dimensional vector spaces
		      (by part b) we can use the rank-nullity theorem (Theorem 2.3).
		      \begin{align*}
			      dim(N(T)) + dim(R(T))               & =   dim(V)        \\
			      dim(W) + dim(\mathrm{V}/\mathrm{W}) & = dim(V)          \\
			      dim(\mathrm{V}/\mathrm{W})          & = dim(V) - dim(W)
		      \end{align*}
		      as desired.
	      \end{proof}
	      }

	      \iffalse
		      Alternate solution that might work but not using the hint.

		      We will prove this fact by creating a basis for $\mathrm{V}/\mathrm{W}$ and computing its dimension.
		      Since $\mathrm{V}$ is a finite dimensional vector space, so $\mathrm{W}$ is also finite dimensional by Theorem 1.11.
		      Let the dimension of $\mathrm{V}$ and $\mathrm{W}$ be denoted by $k$ and $j$, respectively.
		      We can construct a basis $\beta_W$ for $\mathrm{W}$, where $\beta_W = \{u_1, u_2, \cdots, u_j\}$.
		      We can extend $\beta_W$ to be a basis for $\mathrm{V}$ by the corollary of Theorem 1.11.
		      Let this basis be $\beta_V = \{u_1, u_2, \cdots, u_j, u_{j+1}, u_{j+2}, \cdots , u_{k}\}$.
		      We claim that the basis for $\mathrm{V}/\mathrm{W}$ is
		      $\beta_{V/W} = \{u_{j+1} + W, u_{j+2} + W, \cdots , u_{k} + W\}$.
		      \begin{enumerate}[label=\roman*.]
			      \item{
			            $\beta_{V/W}$ is linearly independent
			            \begin{align*}
				            \alpha_{j+1}(u_{j+1} + W) + \alpha_{j+2}(u_{j+2} + W) + \cdots + \alpha_{k}(u_{k} + W) & = \mathbf{0} \\
				            (\alpha_{j+1}u_{j+1} + \alpha_{j+2}u_{j+2} + \cdots + \alpha_{k}u_{k}) + W             & = 0 + W
			            \end{align*}
			            This means that $(\alpha_{j+1}u_{j+1} + \alpha_{j+2}u_{j+2} + \cdots + \alpha_{k}u_{k}) = 0 \in V$.
			            We can rewrite this as $(0u_1 + 0u_2 + \cdots + 0u_j + \alpha_{j+1}u_{j+1} + \alpha_{j+2}u_{j+2} + \cdots + \alpha_{k}u_{k}) = 0$.
			            Thus, $ \alpha_{j+1} = \alpha_{j+2} = \cdots = \alpha_{k} = 0$ because it is written in terms
			            of the basis for $V$. So, $\beta_{V/W}$ is linearly independent.
			            }
			      \item{
			            $\beta_{V/W}$ generates $\mathrm{V}/\mathrm{W}$\\\-\\
			            Let $x = v_x + W$ where $x \in \mathrm{V}/\mathrm{W}, v_x \in V$.
			            \begin{align*}
				            x & = v_x + W                                                                                                                            \\
				              & = (\alpha_1u_1 + \alpha_2u_2 + \cdots + \alpha_ju_j + \alpha_{j+1}u_{j+1} + \alpha_{j+2}u_{j+2} + \cdots + \alpha_{k}u_{k}) + W      \\
				              & =  ((\alpha_1u_1 + \alpha_2u_2 + \cdots + \alpha_ju_j) + (\alpha_{j+1}u_{j+1} + \alpha_{j+2}u_{j+2} + \cdots + \alpha_{k}u_{k})) + W \\
				              & = (\alpha_{j+1}u_{j+1} + \alpha_{j+2}u_{j+2} + \cdots + \alpha_{k}u_{k}) + W                                                         \\
				              & = \alpha_{j+1}(u_{j+1} + W) + \alpha_{j+2}(u_{j+2} + W) + \cdots + \alpha_{k}(u_{k} + W)
			            \end{align*}
			            }
			            Since $\alpha_1u_1 + \alpha_2u_2 + \cdots + \alpha_ju_j \in W$, it can be removed
			            because of $\mathrm{W}$ (the fourth line). So, $\beta_{V/W}$ generates $\mathrm{V}/\mathrm{W}$.
		      \end{enumerate}
		      By definition, $\beta_{V/W}$ is a basis for $\mathrm{V}/\mathrm{W}$.
		      Therefore,
		      \begin{align*}
			      dim(\mathrm{V}/\mathrm{W}) & =  k - j                            \\
			                                 & = dim(\mathrm{V}) - dim(\mathrm{W})
		      \end{align*}
	      \fi



	\item{
	      Let $K = F^n$, define $AK = R(L_A)$, and $A^2K = R(L_{A^2})$.
	      Show that $AK/A^2K$ is a vector space of dimension $rank(A) - rank(A^2)$.
	      \begin{proof}
		      We begin by proving that $AK/A^2K$ is a vector space. It is enough to show that $A^2K$ is a subspace of $AK$
		      to prove that $AK/A^2K$ is a vector space, by part (b). It is clear that $AK$ is a subspace because $AK = R(L_A)$
		      and Theorem 2.3. Moreover, $A^2K \subseteq AK$ because $R(L_{A^2}) \subseteq R(L_A)$. (Theorem 3.7?)
		      $\textbf{Not sure if }  $$R(L_{A^2}) \subseteq R(L_A)$$ \textbf{ holds }$ \\
		      Because $A^2K = R(L_{A^2})$, $A^2K$ has the properties of a vector space because of Theorem 2.1.
		      It follows from part (c) that
		      \begin{align*}
			      dim(AK/A^2K) & = dim(AK) - dim(A^2K))          \\
			                   & = dim(R(L_A)) - dim(R(L_{A^2})) \\
			                   & = rank(A) - rank(A^2)
		      \end{align*}
		      as desired.
	      \end{proof}
	      }
	\item{
	      Show that $A^2K/A^3K$ is a vector space of dimension $rank(A^2) - rank(A^3)$, where $A^3K= R(L_{A^3})$.
	      \begin{proof}
		      Similiar to what we did in part (d), we can prove that $A^2K/A^3K$ is a vector space.
		      Then it follows that,
		      \begin{align*}
			      dim(A^2K/A^3K) & = dim(A^2K) - dim(A^3K))            \\
			                     & = dim(R(L_{A^2})) - dim(R(L_{A^3})) \\
			                     & = rank(A^2) - rank(A^3)
		      \end{align*}
		      as desired.
	      \end{proof}
	      }
	\item{
	      Define $T: AK/A^2K \rightarrow A^2K/A^3K$, by $T(v) = L_A(v)$, i.e, we left multiply each element of $v$ by the matrix $A$.
	      Show that $R(T) = A^2K/A^3K$.
	      \begin{proof}
		      %DO I NEED TO PROVE THAT T IS A LINEAR TRANSFORMATION?

		      To show that $R(T) = A^2K/A^3K$, is another way of saying show that $T$ is onto.
		      We must show that $\forall x \in AK/A^2K [\exists y \in A^2K/A^3K : T(x) = y$].
		      Let $x = Ak' + A^2K$ where $k' \in \mathbb{F}^n$.
		      \begin{align*}
			      T(x) & = T(Ak' + A^2K)              \\
			           & = L_A(Ak' + A^2K)            \\
			           & = L_A(Ak') + L_A(A^2K)       \\
			           & = A^2k' + A^3K \in A^2K/A^3K
		      \end{align*}
		      Therefore, $T$ is onto and $R(T) = A^2K/A^3K$.
	      \end{proof}
	      }
	\item{
	      %DO I NEED TO PROVE THAT T IS A LINEAR TRANSFORMATION?
	      Use the rank-nullity theorem on $T$ to conclude that $rank(A^2) - rank(A^3) \leq rank(A) - rank(A^2)$.
	      \begin{proof}
		      We begin by proving that T is linear. We define $x_1 = Ak'_1 + A^2K$ and $x_2 = Ak'_2 + A^2K$
		      such that $x_1, x_2 \in AK/A^2K$ and $k'_1, k'_2 \in F^n$ and $c \in F$. We use properties of matrices
		      as outlined in Theorem 2.12.
		      \begin{align*}
			      T(ck'_1 + k'_2) & = L_A(ck'_1 + k'_2)                    \\
			                      & = A(ck'_1 + k'_2)                      \\
			                      & = A(c(Ak'_1 + A^2K) + (Ak'_2 + A^2K))  \\
			                      & = A(c(Ak'_1 + A^2K)) + A(Ak'_2 + A^2K) \\
			                      & = c(A(Ak'_1 + A^2K)) + A(Ak'_2 + A^2K) \\
			                      & = cL_A(k'_1)+ L_A(k'_2)                \\
			                      & = cT(k'_1)+ T(k'_2)
		      \end{align*}
		      Since T is linear, we can use rank nullity theorem. From part (d), (e), (f), and assuming that $nullity(T) \geq 0$ because the number of elements of a set cannot be negative
		      \begin{align*}
			      rank(T) + nullity(T)  & = dim(AK/A^2K)           \\
			                            & = rank(A) - rank(A^2)    \\
			      rank(T)               & \leq rank(A) - rank(A^2) \\
			      rank(A^2) - rank(A^3) & \leq rank(A) - rank(A^2)
		      \end{align*}
		      as desired.
	      \end{proof}
	      }
\end{enumerate}

%problem 4
\section{}
Let $\mathrm{V}$ be a finite-dimensional vector space. Let $T$ and $P$ be two linear transformations from $\mathrm{V}$ to itself, such that $T^2= P^2 = 0$, and $T \circ P + P \circ T = I$, where $I$ is the identity in $\mathrm{V}$.
\begin{enumerate}[label=\alph*.]
	\item{
	      Denote $N_T = N(T)$ and $N_P = N(P)$, the null spaces of $T$ and $P$, respectively.
	      Show that $N_P = P(N_T)$, and $N_T = T(N_P)$, where $T(N_P) = \{ T(v): v \in N_P \}$ and $P(N_T) = \{ P(v): v \in N_T \}$.
	      \begin{proof}\
		      \begin{enumerate}[label=\roman*.]
			      \item{
			            Show $N_P = P(N_T)$
			            \begin{enumerate}[label=\arabic*.]
				            \item{
				                  $N_P \subseteq P(N_T)$\\
				                  Let $x \in N_P$. By definition, $P(x) = 0$.
				                  \begin{align*}
					                  P \circ T(x) + T \circ P(x) & = x \\
					                  P \circ T(x) + T(0)         & = x \\
					                  P \circ T(x)                & = x
				                  \end{align*}
				                  Notice that $T(x) \in N_T$, so $x \in P(N_T)$. Thus, $N_p \subseteq P(N_T)$.
				                  }
				            \item{
				                  $P(N_T) \subseteq N_P $\\
				                  Let $P(x) \in P(N_T)$ where $x \in N_T$.\\
				                  $P \circ P(x) = 0$ so $P(x) \in N_P$. Thus, $P(N_T) \subseteq N_P$.
				                  }
			            \end{enumerate}
			            Therfore, $N_P = P(N_T)$.
			            }
			      \item{
			            Show $N_T = T(N_P)$
			            \begin{enumerate}[label=\arabic*.]
				            \item{
				                  $N_T  \subseteq T(N_P)$\\
				                  Let $x \in N_T$. By definition, $T(x) = 0$.
				                  \begin{align*}
					                  P \circ T(x) + T \circ P(x) & = x \\
					                  P(0) + T \circ P(x)         & = x \\
					                  T \circ P(x)                & = x
				                  \end{align*}
				                  Notice that $P(x) \in N_P$, so $x \in T(N_P)$. Thus, $N_T  \subseteq T(N_P)$.
				                  }
				            \item{
				                  $T(N_P) \subseteq N_T$\\
				                  Let $T(x) \in T(N_P)$ where $x \in N_P$.\\
				                  $T \circ T(x) = 0$ so $T(x) \in N_T$. Thus, $T(N_P) \subseteq N_T$.
				                  }
			            \end{enumerate}
			            Therfore, $N_P = P(N_T)$.
			            }
		      \end{enumerate}
	      \end{proof}
	      }
	\item{
	      Show that $\mathrm{V} = N_T \oplus N_P$.
	      \begin{proof}
		      Need to prove the following two conditions.
		      \begin{enumerate}[label=\roman*.]
			      \item{
			            $N_T \cap N_P = \{0\}$.	 \\\-\\
			            Let $x \in N_T$ and $x \in N_P$. This means that $T(x) = 0$ and $P(x) = 0$.
			            \begin{align*}
				            x & = P \circ T(x) + T \circ P(x) \\
				              & = P(0) + T(0)                 \\
				              & = 0
			            \end{align*}
			            Thus, $N_T \cap N_P = \{0\}$.\\
			            }
			      \item{
			            $N_T + N_P = \mathrm{V}$.
			            \begin{enumerate}[label=\arabic*.]
				            \item{
				                  $N_T + N_P \subseteq \mathrm{V}$\\
				                  Let $x \in N_T + N_P$. Define $x = n_t + n_p$ where $n_t \in N_T \subseteq \mathrm{V}$ and $n_p \in N_P \subseteq \mathrm{V}$
				                  by Theorem 2.11. Since $\mathrm{V}$ is a vector space $n_t + n_p \in V$ by closure under addition.\\
				                  Thus, $ x \in \mathrm{V}$ and it follows that $N_T + N_P \subseteq \mathrm{V}$.
				                  }
				            \item{
				                  $\mathrm{V} \subseteq N_T + N_P $\\
				                  Let $x \in V$. We know that $x = P \circ T(x) + T \circ P(x)$.\\
				                  Notice that $P \circ T(x) \in N_P$ because $P(P \circ T(x)) = 0$.\\
				                  Similarly, $T \circ P(x) \in N_T$ because $T(T \circ P(x)) = 0$.\\
				                  Thus, $N_T + N_P \subseteq \mathrm{V}$.
				                  }
			            \end{enumerate}
			            Therefore, $N_T + N_P = \mathrm{V}$.
			            }
		      \end{enumerate}
		      Therefore, by definition $\mathrm{V} = N_T \oplus N_P$.
	      \end{proof}
	      }
	\item{
	      Prove that the dimension of $\mathrm{V}$ is even.
	      \begin{proof}\
		      \begin{lemma}
			      $\mathrm{V} = W_1 \oplus W_2 \Leftrightarrow dim(V) = dim(W_1) + dim(W_2)$\
			      \begin{proof}
				      1.6.29(b) in the textbook
				      $\textbf{Actually remember to type this in}$
			      \end{proof}
		      \end{lemma}
		      By the lemma above, $dim(V) = dim(N_T) + dim(N_P)$.\\
		      Let's construct a basis $\beta_{N_T}$ for $N_T$ and $\beta_{N_P}$ for $N_P$.\\
		      $\beta_{N_T} = \{u_1, u_2, \cdots, u_m\}$\\
		      $\beta_{N_P} = \{w_1, w_2, \cdots, w_n\}$\\
		      From (a), since $N_T = T(N_P)$, this must mean that $$span(\beta_{N_T}) = T(span(\beta_{N_P})) $$ %\subseteq span(\beta_{N_P})
		      Thus, $dim(N_P) \leq dim(N_T)$ because  $dim(T(N_P)) \leq dim(N_P)$.\\
		      Likewise, since $N_P = P(N_T)$, this must mean that $$span(\beta_{N_P}) = P(span(\beta_{N_T})) $$ %\subseteq span(\beta_{N_P})
		      Thus, $dim(N_T) \leq dim(N_P)$ because  $dim(P(N_T)) \leq dim(N_T)$.\\\-\\
		      % $dim(N_T) = m = dim(T(N_P)) \leq n$ and $dim(N_P) = n = dim(P(N_T)) \leq m$\\
		      %FIX 
		      Thus, $dim(N_P) = dim(N_T) = n = m$.
		      \begin{align*}
			      dim(V) & = dim(N_T) + dim(N_P) \\
			             & = n + m               \\
			             & = n + n = m + m       \\
			             & = 2n = 2m
		      \end{align*}

		      Therefore, $dim(V)$ is even.
	      \end{proof}
	      }
	\item{
	      Suppose that the dimension of $\mathrm{V}$ is two. Prove that $\mathrm{V}$ has a basis $\beta$, such that
	      \begin{equation}
		      [T]_{\beta} = \left [ \begin{array}{cc}
				      0 & 1 \\
				      0 & 0
			      \end{array} \right] \qquad \text{ and } \qquad [P]_{\beta} = \left [ \begin{array}{cc}
				      0 & 0 \\
				      1 & 0
			      \end{array} \right] .
	      \end{equation}
	      \begin{proof}

	      \end{proof}
	      }
\end{enumerate}

\end{document}